\subsection{Improving Cache Performance}

One of the main challenges in memory system design is achieving \textbf{low-latency memory access} while maintaining \textbf{high throughput and efficiency}. Since memory is a major performance bottleneck, architects aim to \textbf{minimize delays caused by cache misses}.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Key Metric: Average Memory Access Time (AMAT)}}
\end{flushleft}
The \definition{Average Memory Access Time (AMAT)} equation \textbf{defines how effective a memory hierarchy is}:
\begin{equation}
    \text{AMAT} = \text{Hit Time} + \text{Miss Rate} \times \text{Miss Penalty}
\end{equation}
Each term in this formula captures a different aspect of performance:
\begin{itemize}
    \item \definition{Hit Time}: Time to access data in the cache (when it's a hit).
    
    The \hl{unit is cycles}.
    \item \definition{Miss Rate}: Fraction of memory accesses that result in a miss.
    
    The \hl{unit is \%}.
    \item \definition{Miss Penalty}: Time to fetch data from the next memory level.
    
    The \hl{unit is cycles}.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{bullseye} \textbf{Goal: Minimize AMAT}}
\end{flushleft}
We can improve cache performance through \textbf{three orthogonal strategies}, each targeting one component of AMAT:
\begin{enumerate}
    \item \textbf{Reduce Miss Rate}. This means \hl{making the cache \emph{more effective} in storing the right data}. \textbf{Techniques include}:
    \begin{itemize}
        \item Larger caches.
        \item Larger blocks (but with care).
        \item Higher associativity.
        \item Software and hardware prefetching.
        \item Compiler optimizations.
    \end{itemize}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Result:}} fewer accesses go to slower memory levels.
    \item \textbf{Reduce Miss Penalty}. Once a miss happens, the delay can be high. We aim to \textbf{reduce the time spent waiting} by:
    \begin{itemize}
        \item Prioritizing reads.
        \item Using victim caches.
        \item Sub-blocking.
        \item Early restart or critical word first.
        \item Second-level caches.
        \item Non-blocking caches.
    \end{itemize}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Result:}} the \emph{impact} of a miss is reduced.
    \item \textbf{Reduce Hit Time}. Even on a hit, we want the \textbf{fastest possible access}. This can be achieved by:
    \begin{itemize}
        \item Making the L1 cache small and simple.
        \item Avoiding address translation delays.
        \item Using pipelined writes.
        \item Virtually-indexed, physically-tagged caches.
    \end{itemize}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Result:}} faster access when hit, then lower AMAT baseline.
\end{enumerate}

\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l l l @{}}
        \toprule
        Strategy & Targeted Term & Goal \\
        \midrule
        Reduce Miss Rate    & Miss Rate     & Prevent misses from occurring \\ [.3em]
        Reduce Miss Penalty & Miss Penalty  & Make misses less costly       \\ [.3em]
        Reduce Hit Time     & Hit Time      & Make hits as fast as possible \\
        \bottomrule
    \end{tabular}
\end{table}