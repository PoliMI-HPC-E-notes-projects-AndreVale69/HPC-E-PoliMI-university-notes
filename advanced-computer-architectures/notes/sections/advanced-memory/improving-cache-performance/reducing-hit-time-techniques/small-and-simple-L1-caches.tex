\subsubsection{Reducing Hit Time Techniques}

\paragraph{Small and Simple L1 Caches}

Even if a cache hit is \textbf{much faster than a miss}, it still lies on the \textbf{critical path} of every memory access. The \textbf{L1 cache} is accessed \textbf{every CPU cycle}, so even a \textbf{1-cycle delay} in hit time can slow down the processor's maximum clock frequency.

\highspace
\textcolor{Green3}{\faIcon{check-circle} \textbf{Idea:}} Keep the L1 cache \textbf{small and simple} so that:
\begin{itemize}
    \item Tag comparison is quick.
    \item Access time is minimal.
    \item It can run at the CPU's full clock speed.
\end{itemize}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{\speedIcon} \textbf{Why Small Caches Are Faster}}
\end{flushleft}
\begin{itemize}
    \item \textbf{Shorter wires} inside the cache array.
    \item Fewer sets $\rightarrow$ simpler indexing logic.
    \item Smaller tag array $\rightarrow$ faster tag comparison.
    \item Lower associativity $\rightarrow$ fewer parallel tag comparators.
\end{itemize}

\begin{examplebox}
    A 32KB, 8-way L1 cache might take \textbf{2-3 cycles} to access.
    A 16KB, direct-mapped L1 cache could be accessed in \textbf{1 cycle}.
    The smaller L1 will have a \textbf{higher miss rate}, but the much lower hit time may still \textbf{improve overall AMAT}.
\end{examplebox}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{balance-scale} \textbf{Trade-off: Miss Rate vs. Hit Time}}
\end{flushleft}

\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l l l @{}}
        \toprule
        Cache Size & Hit Time & Miss Rate \\
        \midrule
        Small & \textcolor{Green3}{\faIcon{check}} Low & \textcolor{Red2}{\faIcon{times}} High \\ [.3em]
        Large & \textcolor{Red2}{\faIcon{times}} High & \textcolor{Green3}{\faIcon{check}} Low \\
        \bottomrule
    \end{tabular}
\end{table}

\noindent
This is why L1 caches are \textbf{small} (16-64 KB) and \textbf{fast}, while \textbf{L2/L3 caches} are much larger but slower.

\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{Design Practice}}
\end{flushleft}
\begin{itemize}
    \item Keep \textbf{L1 cache} small enough for \textbf{1-cycle accesses} at CPU clock speed.
    \item Use \textbf{L2 and L3 caches} to absorb most misses from L1.
    \item Choose associativity carefully, often \textbf{2-4 way} in L1 to keep hit time low.
\end{itemize}
A \textbf{small and simple L1 cache} ensures \textbf{minimum hit time}, allowing the CPU to run at full speed. Although the miss rate is slightly higher, the \textbf{overall performance} often improves because the \textbf{baseline access time} is much lower.