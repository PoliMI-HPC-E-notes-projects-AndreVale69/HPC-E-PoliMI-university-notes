\paragraph{Increasing Associativity}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{What is Associativity?}}
\end{flushleft}
In the cache memory context, \definition{Cache Associativity} describes \textbf{how many places in the cache a given block of main memory can be stored}. It answer the question: ``\emph{if we need to store this memory block in the cache, how many cache locations are possible candidates?}''. There are three main types:
\begin{itemize}
    \item \textbf{Direct-Mapped} (page \pageref{def: Direct-Mapped Cache}): Associativity $=$ 1.
    \item \textbf{Fully Associative} (page \pageref{def: Fully Associative Cache}): Associativity $=$ Number of lines in the cache.
    \item \textbf{N-Way Set-Associative} (page \pageref{def: n-way set-associative cache}): Associativity $=$ \emph{n}-way, with $n > 1$.
\end{itemize}
So, associativity is essentially the ``number of candidate cache lines per set'' that a block can occupy. Higher associativity reduces conflict misses but increases hardware cost and lookup time.

\highspace
In \textbf{direct-mapped caches} (page \pageref{def: Direct-Mapped Cache}), each memory block maps to exactly \textbf{one cache location}. This simplicity results in \textbf{fast access}, but it can also cause many \textbf{conflict misses}, especially when multiple frequently used addresses map to the same index.

\highspace
\textcolor{Green3}{\faIcon{check-circle} \textbf{Solution:}} Use \textbf{set-associative caches} (page \pageref{def: n-way set-associative cache}), where each set contains \textbf{multiple slots (ways)} for blocks to be stored. This \textbf{reduces conflicts} by offering \textbf{more choices} for where a block can go.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Terminology Refresher}}
\end{flushleft}
\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l p{22em} @{}}
        \toprule
        Cache Type & Behavior \\
        \midrule
        \textbf{Direct-Mapped}          & 1 block per set (1-way associative). \\ [.3em]
        \textbf{2-Way Set-Associative}  & 2 blocks per set. \\ [.3em]
        \textbf{Fully Associative}      & Any block can go anywhere in the cache (all in one set). \\
        \bottomrule
    \end{tabular}
\end{table}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Effect on Miss Rate}}
\end{flushleft}
\begin{itemize}
    \item As associativity increases, \textbf{conflict misses decreases}.
    \item \textbf{Capacity and compulsory misses stay the same}.
    \item \textbf{Fully associative caches} (page \pageref{def: Fully Associative Cache}) \textbf{eliminate all conflict misses}, but they are expensive and slower.
\end{itemize}

\begin{examplebox}
    If the cache is direct-mapped, these blocks \textbf{overwrite each other}, causing many \textbf{conflict misses}:
    \begin{lstlisting}[language=c, mathescape=true]
a[i] $\rightarrow$ cache set 5
b[i] $\rightarrow$ cache set 5
c[i] $\rightarrow$ cache set 5\end{lstlisting}
    But with a \textbf{4-way set-associative cache}, all 3 blocks could coexist in \textbf{set 5}, avoiding those misses.
\end{examplebox}

\highspace
\begin{flushleft}
    \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Trade-offs and Drawbacks}}
\end{flushleft}
\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l p{17em} @{}}
        \toprule
        Trade-Off & Effect \\
        \midrule
        \textbf{Hit Time Increases}             & More ways $=$ more tag comparisons $=$ slower access. \\ [.3em]
        \textbf{Area and Complexity Increase}   & More comparators, multiplexers, and logic. \\ [.3em]
        \textbf{Power Usage Increases}          & More hardware is active on each access. \\
        \bottomrule
    \end{tabular}
\end{table}

\noindent
\textbf{Design trade-off}: There's a \textbf{sweet spot}; usually \textbf{2-way or 4-way} associativity gives good results without hurting hit time too much.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Rule of Thumb: 2:1 Cache Rule}}
\end{flushleft}
A \textbf{direct-mapped cache of size $N$} has \textbf{about the same miss rate} as a \textbf{2-way set-associative cache of size} $\dfrac{N}{2}$. This tells us that we can \textbf{trade associativity for size}: higher associativity sometimes compensates for a smaller cache.

\highspace
In general, increasing associativity \textbf{reduces conflict misses} by allowing more blocks to coexist in the same set, but it comes at the cost of \textbf{higher hit time, area, and power}. Designers must \textbf{balance associativity with hit time} and hardware complexity.