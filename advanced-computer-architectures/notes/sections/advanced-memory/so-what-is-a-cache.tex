\subsection{So, what is a Cache?}

\begin{definitionbox}[: Cache]
    A \definition{Cache} is a small, fast \textbf{memory} located \textbf{close to the processor} that temporarily \textbf{stores copies of data from the main memory}, aiming to reduce the average time needed to access data and instructions.
\end{definitionbox}

\noindent
Modern memory systems are structured hierarchically:
\begin{itemize}
    \item \important{Cache (upper level)}: small, fast, but expensive (SRAM). It is very close to the CPU and stores a subset of main memory to reduce access latency.
    
    \item \important{Main memory (lower level)}: larger, slower, but cheaper (DRAM). It stores the complete working set and is accessed only if data is not found in cache.
\end{itemize}
The cache acts as a \textbf{buffer} between fast CPU and slow main memory.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Terminology}}
\end{flushleft}
\begin{itemize}
    \item \definition{Cache Block} or \definition{Cache Line}. The smallest unit of data transferred between memory and cache. It is typically 32 to 128 bytes. Since a cache is divided into multiple blocks, we use:
    \begin{equation}
        \text{Number of blocks} = \dfrac{\text{Cache size}}{\text{Block size}}
    \end{equation}
    To calculate the number of blocks in the cache.

    \begin{examplebox}
        With a 64 KB cache, and 16-byte per block:
        \begin{equation*}
            \dfrac{64 \times 1024}{16} = 4096 \,\text{blocks}
        \end{equation*}
    \end{examplebox}


    \item[\textcolor{Green3}{\faIcon{check}}] \definition{Cache Hit}. Occurs when the requested memory address is \textbf{already present in the cache}. Fast access, minimal latency.
    

    \item[\textcolor{Red2}{\faIcon{times}}] \definition{Cache Miss}. Occurs when the requested address is \textbf{no in the cache}. The block must be fetched from lower-level memory.

    \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Consequences of a miss}}
    \begin{enumerate}
        \item \textbf{Stall} CPU.
        \item Fetch block from memory.
        \item \textbf{Write} block to cache.
        \item Retry access (which now becomes a hit).
    \end{enumerate}


    \newpage


    \item \definition{Hit Time}. It is the time to:
    \begin{enumerate}
        \item Access the cache.
        \item Determine if it's a hit.
        \item Return data (if present).
    \end{enumerate}
    It is fast, typically 1-3 CPU cycles.


    \item \definition{Miss Penalty}. It is the time to:
    \begin{enumerate}
        \item Fetch the block from main memory (or next-level cache).
        \item Update cache.
        \item Resume the CPU.
    \end{enumerate}
    Much \textbf{slower} than hit time, often 10s to 100s of cycles.


    \item \definition{Average Memory Access Time (AMAT)}
    \begin{equation}
        \text{AMAT} = \text{Hit Time} + \text{Miss Rate} \times \text{Miss Penalty}
    \end{equation}
    This is the \textbf{expected cost of accessing memory}, accounting for both hits and misses.
    \begin{examplebox}
        For example:
        \begin{itemize}
            \item Hit Time: 1 cycle.
            \item Miss Rate: 5\%.
            \item Miss Penalty: 100 cycles.
        \end{itemize}
        \begin{equation*}
            \text{AMAT} = 1 + 0.05 \times 100 = 6 \text{ cycles}
        \end{equation*}
    \end{examplebox}
\end{itemize}