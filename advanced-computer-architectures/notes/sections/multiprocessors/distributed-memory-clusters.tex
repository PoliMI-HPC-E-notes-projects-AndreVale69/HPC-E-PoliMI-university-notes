\subsection{Distributed-memory clusters}

A \definition{Cluster} is a set of independent computers (called nodes), each with:
\begin{itemize}
    \item Its \textbf{own processors} (often multicore CPUs).
    \item Its \textbf{own private memory} (not shared with others).
    \item Local disk and OS instance.
\end{itemize}
Nodes are connected via a \textbf{scalable interconnection network} (Ethernet, InfiniBand, high-speed fabrics). Unlike DSM/CC-NUMA, here there is \textbf{no shared address space}. Each node has its \textbf{own private address space}, and memory of one node cannot be directly accessed by another node via loads/stores.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{How can two nodes communicate?}}
\end{flushleft}
Communication between nodes happens via \textbf{explicit message passing}:
\begin{itemize}
    \item A process in Node A calls \texttt{send(message, Node B)}.
    \item A process in Node B calls \texttt{receive(message, Node A)}.
\end{itemize}
The software support is MPI (Message Passing Interface), the de facto standard in HPC.

\begin{deepeningbox}[: MPI]
    \definition{MPI (Message Passing Interface)} is a \textbf{standardized library interface} for communication in distributed-memory systems. It defines how \textbf{processes exchange messages} (data) explicitly, so they can work together on a parallel program.  It is not a language, but a \textbf{specification $+$ libraries} available in C, C++, Fortran, Python bindings, etc.

    \highspace
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{question-circle} \textbf{Why MPI exists}}
    \end{flushleft}
    In \textbf{distributed-memory clusters}, processes do \textbf{not share memory}. Each process only sees its \textbf{own private address space}. To cooperate, processes must \textbf{send and receive messages} across the interconnect. MPI standardizes this, so parallel programs are \textbf{portable} across machines and vendors.
\end{deepeningbox}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{When to use distributed-memory clusters}}
\end{flushleft}
\begin{itemize}
    \item \textbf{Scalability}: Clusters can grow from a few nodes to tens of thousands of nodes. Adding memory is easy, each node brings its own DRAM.
    \item \textbf{Commodity hardware}: Built from off-the-shelf PCs/servers connected with networking gear. Cheaper than custom supercomputers.
    \item \textbf{HPC workloads}: Large-scale scientific computing (climate simulation, astrophysics, molecular dynamics). Data analytics, AI training at scale.
    \item \textbf{Cloud datacenters}: The dominant architecture, each server is one node, applications distribute data across them.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Pros}} \textbf{and} \textcolor{Red2}{\faIcon{times-circle} \textbf{Cons}}
\end{flushleft}
\begin{itemize}
    \item[\textcolor{Green3}{\faIcon{check-circle}}] \textcolor{Green3}{\textbf{Advantages}}
    \begin{itemize}
        \item[\textcolor{Green3}{\faIcon{check}}] Easy to scale: just add more nodes.
        \item[\textcolor{Green3}{\faIcon{check}}] Memory grows linearly with the number of nodes.
        \item[\textcolor{Green3}{\faIcon{check}}] Fault isolation: one node can fail without crashing the whole system.
        \item[\textcolor{Green3}{\faIcon{check}}] Cheaper and easier to build with commodity hardware.
    \end{itemize}
    \item[\textcolor{Red2}{\faIcon{times-circle}}] \textcolor{Red2}{\textbf{Disadvantages}}
    \begin{itemize}
        \item \textbf{Programming is harder}: No shared memory; programmer must explicitly partition data and orchestrate communication. Think in terms of ``who owns the data'' and ``when to send it''.
        \item \textbf{Communication costs are high}: Network latency is much larger than local memory access. Bandwidth between nodes is lower than bandwidth to local DRAM.
        \item \textbf{Synchronization overhead}: Every send/receive pair involves coordination.
    \end{itemize}
\end{itemize}