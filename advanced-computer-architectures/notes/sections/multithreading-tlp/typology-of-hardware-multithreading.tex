\subsection{Typology of Hardware Multithreading}

\definition{Hardware Multithreading} is a technique used in modern processors to improve resource utilization and overall throughput by \textbf{allowing multiple threads to be executed concurrently within a single core}.

\highspace
This section introduces the main types of hardware multithreading:
\begin{itemize}
    \item \definition{Coarse-Grained Multithreading (CGMT)}. The processor executes one thread until it hits a \textbf{long-latency stall} (e.g., cache miss to DRAM). Then it \textbf{switches to another thread}. The switch requires \textbf{draining/refilling the pipeline}, which costs a few cycles, but that's negligible compared to hundreds of cycles of stall.
    \begin{itemize}
        \item[\textcolor{Green3}{\faIcon{check-circle}}] \textcolor{Green3}{\textbf{Advantages}}
        \begin{itemize}
            \item[\textcolor{Green3}{\faIcon{check}}] Very \textbf{simple to implement} (just duplicate PC $+$ registers).
            \item[\textcolor{Green3}{\faIcon{check}}] Effective at hiding \emph{long} stalls (memory, I/O).
        \end{itemize}

        \item[\textcolor{Red2}{\faIcon{times-circle}}] \textcolor{Red2}{\textbf{Disadvantages}}
        \begin{itemize}
            \item[\textcolor{Red2}{\faIcon{times}}] Useless against \emph{short} stalls (like data hazards or branch mispredicts).
            \item[\textcolor{Red2}{\faIcon{times}}] Pipeline bubbles still occur frequently.
        \end{itemize}
    \end{itemize}

    \begin{examplebox}[: CGMT Analogy]
        Imagine one cashier per supermarket checkout. When a cashier has to wait for a price check (long stall), they temporarily leave and another cashier steps in. But for small pauses (handing change), the switch isn't worth it.
    \end{examplebox}
    

    \item \definition{Fine-Grained Multithreading (FGMT)}. The processor \textbf{switches\break thread every cycle} (usually round-robin). If one thread is stalled, it's skipped. Each thread makes slower progress (because it only issues one instruction every few cycles), but the \textbf{pipeline never sits idle}.
    \begin{itemize}
        \item[\textcolor{Green3}{\faIcon{check-circle}}] \textcolor{Green3}{\textbf{Advantages}}
        \begin{itemize}
            \item[\textcolor{Green3}{\faIcon{check}}] \textbf{Hides all kinds of stalls}, even short ones.
            \item[\textcolor{Green3}{\faIcon{check}}] Keeps functional units busy almost every cycle.
        \end{itemize}

        \item[\textcolor{Red2}{\faIcon{times-circle}}] \textcolor{Red2}{\textbf{Disadvantages}}
        \begin{itemize}
            \item[\textcolor{Red2}{\faIcon{times}}] Increases \textbf{per-thread latency} (our program feels slower if it's the only one running).
            \item[\textcolor{Red2}{\faIcon{times}}] Requires very fast thread-selection logic.
        \end{itemize}
    \end{itemize}

    \begin{examplebox}[: CGMT Analogy]
        Imagine a classroom where students (threads) answer questions in strict rotation. Even if one student hesitates, the next gets the turn immediately, so the teacher (pipeline) never waits.
    \end{examplebox}


    \item \definition{Simultaneous Multithreading (SMT)}. The processor is \textbf{wide superscalar} (can issue 4-8 instructions per cycle). But one thread alone rarely fills all slots (ILP limit). So the CPU can issue instructions from \textbf{different threads in the same cycle}. Combines ILP (multiple instructions per thread) and TLP (multiple threads).
    \begin{itemize}
        \item[\textcolor{Green3}{\faIcon{check-circle}}] \textcolor{Green3}{\textbf{Advantages}}
        \begin{itemize}
            \item[\textcolor{Green3}{\faIcon{check}}] Maximizes \textbf{throughput per cycle}.
            \item[\textcolor{Green3}{\faIcon{check}}] Utilizes execution units that would otherwise be idle.
        \end{itemize}

        \item[\textcolor{Red2}{\faIcon{times-circle}}] \textcolor{Red2}{\textbf{Disadvantages}}
        \begin{itemize}
            \item[\textcolor{Red2}{\faIcon{times}}] Threads compete for shared resources (caches, ALUs, branch predictors).
            \item[\textcolor{Red2}{\faIcon{times}}] Per-thread performance can vary unpredictably (depends on\break what the sibling thread does).
            \item[\textcolor{Red2}{\faIcon{times}}] Hardware complexity is high (must decide \emph{which thread's instructions} win each slot).
        \end{itemize}
    \end{itemize}

    \begin{examplebox}[: CGMT Analogy]
        Think of a wide highway with 8 lanes (issue slots). A single car (thread) can't use them all. With multiple cars (threads), the lanes are filled more efficiently, but they can also block each other if not well managed.
    \end{examplebox}
\end{itemize}
The figure \ref{fig: Execution Slot Utilization}, page \pageref{fig: Execution Slot Utilization}, makes clear the \textbf{design philosophy shift} we introduced in Section \ref{subsection: Multithreading Basics}, page \pageref{subsection: Multithreading Basics}.
\begin{itemize}
    \item In the \textbf{superscalar single-thread case}, the CPU tries to minimize \emph{latency} for one thread, but many execution slots remain empty due to ILP limits.
    \item \textbf{Coarse-grain multithreading} improves throughput only when a thread is completely blocked by a long stall, but short stalls still waste slots.
    \item \textbf{Fine-grain multithreading} fills the pipeline continuously, maximizing \textbf{throughput} but stretching \emph{per-thread latency} (since each thread issues less often).
    \item \textbf{SMT} goes further: by issuing multiple threads simultaneously, it combines ILP and TLP to achieve the \textbf{highest throughput}, at the cost of unpredictable latency per thread (threads interfere for shared resources).
\end{itemize}
Thus, the figure visually captures the \textbf{central idea of multithreading}: stop focusing exclusively on speeding up a \emph{single} thread (ILP); instead, keep the core busy across \emph{multiple} threads, so the processor's valuable resources are rarely idle.

\newpage

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\textwidth]{img/execution-slot-utilization.pdf}
    \captionsetup{singlelinecheck=off}
    \caption[]{Execution Slot Utilization.\cite{hennessy2017computer} This figure shows \textbf{how a superscalar pipeline's issue slots are used} under four scenarios:
    \begin{enumerate}
        \item \textbf{Superscalar without multithreading}. Only one thread. Many slots are \textbf{empty} (white) because the single thread suffers stalls: dependencies, cache misses, branch mispredicts. Even if the core is 4-issue wide, often only 1-2 instructions can issue per cycle.


        \item \textbf{Coarse-Grained Multithreading (CGMT)}. The figure shows long stretches of slots in one color (Thread A), then a big stall (white), then long stretches in another color (Thread B). Here, each thread runs until it encounters a long stall (e.g., a memory miss). Then the hardware switches to another thread. Empty slots still exist between switches, because the pipeline must ``drain/refill''.
        

        \item \textbf{Fine-Grained Multithreading (FGMT)}. Threads alternate every cycle (different colors interleaved). This keeps slots filled continuously, even if one thread stalls. However, each thread progresses more slowly, since it only issues every $N$ cycles (with $N$ threads).
        

        \item \textbf{Simultaneous Multithreading (SMT)}. Multiple threads share the pipeline \textbf{within the same cycle}. Different colors appear \textbf{side-by-side in the same cycle row}, showing two (or more) threads issuing simultaneously. This achieves the \textbf{highest utilization} of slots: both ILP (within one thread) and TLP (across threads) contribute to filling the issue width.
    \end{enumerate}
    In the superscalar case, black represents one reference thread, gray represents instructions from different threads, and white represents empty slots, i.e., unused pipeline capacity.}
    \label{fig: Execution Slot Utilization}
\end{figure}

\vspace{-1em}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{history} \textbf{Summary}}
\end{flushleft}
\begin{itemize}
    \item \textbf{Coarse-Grain MT:} simple, hides \emph{long} stalls only.
    \item \textbf{Fine-Grain MT:} frequent switching, hides \emph{all} stalls, but per-thread latency grows.
    \item \textbf{SMT:} most advanced, fills superscalar issue slots with multiple threads, best throughput, but high complexity and contention.
\end{itemize}