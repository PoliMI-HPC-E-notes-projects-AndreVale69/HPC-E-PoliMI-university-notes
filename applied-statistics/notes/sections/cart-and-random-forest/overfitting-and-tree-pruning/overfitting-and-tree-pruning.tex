\subsection{Overfitting and Tree Pruning}

When we build a decision tree, we face a \textbf{bias-variance tradeoff}:
\begin{itemize}
    \item \textbf{Too few splits}: only a few big regions (shallow tree).
    
    The risk here is \hl{oversmoothing} (high bias). The tree is too simple to capture patterns. Consequently, predictions are inaccurate or imprecise.


    \item \textbf{Too many splits}: lots of small regions (deep tree).
    
    The risk here is \hl{overfitting} (high variance). The tree is too complex, and it fits training data too closely. It learns \textbf{noise} rather than true structure, so we have poor generalization.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{cut} \textbf{Tree Pruning Concept}}
\end{flushleft}
\definition{Tree Pruning} is the process of \textbf{cutting back} a large, complex tree to avoid overfitting.
\begin{itemize}
    \item Instead of stopping early, we \textbf{grow a large tree first} (possibly overfitted).
    \item Then we \textbf{prune} it by \textbf{\emph{removing branches}} that \textbf{don't improve prediction enough}.
\end{itemize}
This produces a \textbf{simpler subtree} with better generalization.

\highspace
Tree Pruning is the standard pruning method used in CART (Classification and Regression Trees). The idea is to \textbf{balance accuracy and complexity} by minimizing a \textbf{penalized error}:
\begin{equation}
    C_\alpha\left(T\right) = \text{RSS}\left(T\right) + \alpha \cdot \left|T\right|
\end{equation}
Where:
\begin{itemize}
    \item $T$: the tree.
    \item $\text{RSS}(T)$: total Residual Sum of Squares for the tree.
    \item $\left|T\right|$: number of terminal nodes (leaves).
    \item $\alpha \geq 0$: \textbf{complexity parameter} (or \textbf{tuning parameter}), controls how much we penalize tree size.
    \begin{itemize}
        \item If $\alpha = 0$: we just minimizez RSS (prefer big trees with \hl{risk of overfitting}).
        \item If $\alpha$ is large: we heavily penalize large trees (prefer small trees with \hl{risk of underfitting}).
    \end{itemize}
    By adjusting $\alpha$, we can \textbf{find the right balance}.
\end{itemize}