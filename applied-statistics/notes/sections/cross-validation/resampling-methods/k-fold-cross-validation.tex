\subsubsection{K-Fold Cross-Validation}\label{subsubsection: K-Fold Cross-Validation}

\definition{K-Fold Cross-Validation} is a \textbf{resampling method} used to:
\begin{itemize}
    \item Estimate the \textbf{test error}.
    \item Select the \textbf{best model}.
    \item Avoid wasting data on a single validation split.
\end{itemize}
It's the \textbf{most widely used method} in practice for model evaluation and selection.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{Algorithm}}
\end{flushleft}
\begin{enumerate}
    \item \textbf{Split} the dataset into $K$ approximately equal-sized, disjoint subsets\break (called \emph{folds}): $C_1, C_2, \dots, C_K$.
    \item For each fold $k = 1, 2, \dots, K$:
    \begin{enumerate}
        \item Use all the data \textbf{except} $C_k$ to train the model.
        \item Use the fold $C_k$ to test the model.
        \item Compute the prediction error (e.g., MSE) on $C_k$.
    \end{enumerate}
    \item \textbf{Average} the errors over all $K$ iterations (\emph{standard case}):
    \begin{equation}
        \text{CV}_K = \frac{1}{K} \cdot \sum_{k=1}^K \text{MSE}_k
    \end{equation}
    \hl{This average is our estimate of the \textbf{test error}.} However, if the \textbf{folds have different sizes} $n_k$, the correct weighted version is:
    \begin{equation}
        \text{CV}_K = \sum_{k=1}^K \left( \dfrac{n_k}{n} \cdot \text{MSE}_k \right)
    \end{equation}
    Where $n_k$ is the number of observations in fold $k$, and $n = \displaystyle\sum_{k=1}^K n_k$.
    
    This ensures that each observation contributes equally to the final CV error estimates.
\end{enumerate}
So each observation is used $K-1$ times for training and $1$ time for validation. This gives a \textbf{low-variance} estimate of model performance, and avoids over-relying on one particular split.

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{How many $K$ subsets do we need?}}
\end{flushleft}
We want:
\begin{itemize}[label=\textcolor{Green3}{\faIcon{check}}]
    \item Low \textbf{bias} (so the estimate reflects the true test error)
    \item Low \textbf{variance} (so the estimate is stable across datasets)
\end{itemize}
But as $K$ increases:
\begin{itemize}
    \item We train on more data $\Rightarrow$ \textbf{lower bias}.
    \item We validate on less data $\Rightarrow$ \textbf{higher variance}.
    \item We do more folds $\Rightarrow$ \textbf{more computation}.
\end{itemize}

\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l l l l p{9em} @{}}
        \toprule
        $K$ value & Bias & Variance & Computation & Notes \\
        \midrule
        \textbf{2-4}                                        & High      & Low       & Very fast     & Crude estimate, not recommended. \\ [.5em]
        \textbf{5 or 10} \textcolor{Green3}{\faIcon{check}} & Moderate  & Moderate  & Reasonable    & Standard choices in practice. \\ [.5em]
        $K = n$                                             & Very low  & High      & Very slow     & Best theoretical bias, but often unstable. \\
        \bottomrule
    \end{tabular}
    \caption{Tradeoffs: how $K$ affects performance.}
\end{table}

\noindent
\textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Warning:}} If $K = n$ the method is the Leave-One-Out CV (see page \pageref{subsubsection: Leave-One-Out CV - LOOCV}).

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Practical Recommendations}}
\end{flushleft}
\begin{itemize}
    \item Use $K = 5$ if:
    \begin{itemize}
        \item We have a \textbf{large dataset}.
        \item Speed is important.
        \item We want a \textbf{quick, stable} estimate.
    \end{itemize}
    \item Use $K = 10$ if:
    \begin{itemize}
        \item We have a \textbf{moderate-sized dataset}.
        \item We need a \textbf{more accurate} estimate of test error.
        \item We're doing \textbf{model selection or tuning}.
    \end{itemize}
    \item \textbf{Avoid very large} $K$ unless:
    \begin{itemize}
        \item We're doing research.
        \item We specifically need LOOCV properties.
        \item We have \textbf{very few samples}.
    \end{itemize}
    People sometimes think ``more folds is better''. However, as $K$ is increased, the \textbf{validation sets become smaller}, leading to more \textbf{noisy error estimates}. Plus, it's \textbf{computationally expensive} for complex models.
\end{itemize}