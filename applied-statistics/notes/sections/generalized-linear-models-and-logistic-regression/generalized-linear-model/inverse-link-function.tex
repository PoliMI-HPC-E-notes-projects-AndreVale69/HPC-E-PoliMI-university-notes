\subsubsection{Inverse Link Function}

In a \textbf{GLM}, we do not model the mean $E[Y]$ directly, we model \textbf{the link of the mean}:
\begin{equation*}
    g(E[Y]) = X^T \beta
\end{equation*}
To get the actual mean back on its \textbf{natural scale}, we apply the \definition{Inverse Link Function}:
\begin{equation}
    E[Y] = g^{-1}(X^T \beta)
\end{equation}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Why it matters}}
\end{flushleft}
\begin{itemize}
    \item The \textbf{link function} transforms the mean to make a linear model possible.
    \item The \textbf{inverse link} undoes this transformation so we get predictions in the real-world units we care about.
\end{itemize}
\textcolor{Green3}{\faIcon{thumbs-down} \textbf{We are still not convinced. Why do we need the original scale?}} It's simply because we \textbf{can't interpret log-odds intuitively}. If we tell a client ``the log-odds is 1.4'', no one knows what that means. But if we tell them ``the probability of success is 80\%'', that's meaningful. So the workflow is:
\begin{enumerate}
    \item Model the \textbf{link of the mean} linearly (e.g., $\mathrm{logit}(p) = X^T \beta$).
    \item Estimate $\beta$ by fitting this transformed model.
    \item Use the \textbf{inverse link} (e.g., sigmoid) to transform the result back. It gives valid probability.
    \item Make decisions with the actual probability!
\end{enumerate}
In other words, the link is for the math, and the inverse link is for meaningful output. If we never invert the link we only have the transformed mean which by itself is useless for practical interpretation.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{stream} \textbf{Types of inverse link functions}}
\end{flushleft}
\begin{itemize}
    \item \definition{Identity Link} (Linear Regression). Its link is:
    \begin{equation*}
        g(\mu) = \mu
    \end{equation*}
    And the inverse link function is:
    \begin{equation}
        g^{-1}(z) = z
    \end{equation}
    Nothing changes! The result is: $E[Y] = X^T \beta$.


    \item \definition{Logit Link} (Logistic Regression). Its link is:
    \begin{equation*}
        g(p) = \log \left( \frac{p}{1 - p} \right)
    \end{equation*}
    And the inverse link function is:
    \begin{equation}\index{Sigmoid}
        g^{-1}(z) = \dfrac{1}{1 + e^{-z}} \quad (\text{sigmoid})
    \end{equation}
    The result is:
    \begin{equation*}
        P(Y = 1 | X) = \text{sigmoid}(X^T \beta)
    \end{equation*}

    \newpage

    \begin{figure}[!htp]
        \centering
        \includegraphics[width=.9\textwidth]{img/glm/sigmoid-function.pdf}
        \captionsetup{singlelinecheck=off}
        \caption[]{Example of \textbf{sigmoid curve}. We can see its classic S-shape.
        \begin{itemize}
            \item For large negative $z$, the output $p$ stays close to $0$.
            \item For large positive $z$, the output $p$ stays close to $1$.
            \item At $z = 0$, it crosses $p = 0.5$.
        \end{itemize}
        So no matter how large or small our linear predictor $z = X^T \beta$ is, the sigmoid safely squashes it into a valid probability.}
    \end{figure}
    

    \item \definition{Log Link} (Poisson Regression). Its link is:
    \begin{equation*}
        g(\lambda) = \log(\lambda)
    \end{equation*}
    And the inverse link function is:
    \begin{equation}
        g^{-1}(z) = e^z \quad (\text{exponential})
    \end{equation}
    The result is:
    \begin{equation*}
        E[Y] = \lambda = \exp(X^T \beta)
    \end{equation*}
\end{itemize}
So \textbf{every link function has an inverse}. The link is for safe modeling, and the inverse gives us the actual prediction in meaningful units.