\subsection{Model Evaluation}

After fitting the regression line, the next question is: \emph{how good is the model at explaining the data?} That's what this section is about.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Goal of Model Evaluation}}
\end{flushleft}
We want to understand:
\begin{enumerate}
    \item How much of the variation in $Y$ is \textbf{explained} by the model?
    \item How much remains \textbf{unexplained} (random noise or poor fit)?
\end{enumerate}
This leads to the \textbf{decomposition of variance} and the \textbf{coefficient of determination} $R^{2}$.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Variance Decomposition}}
\end{flushleft}
We break down the total variability in the output $Y$ into:
\begin{itemize}
    \item \definition{Regression Sum of Squares (SSR)} (or explained sum or squares)
    \begin{equation}
        \text{SSR} = \displaystyle\sum_{i=1}^{n}\left(\hat{Y}_{i} - \bar{Y}\right)^{2}
    \end{equation}
    Measures how much of the variability in $Y$ is \textbf{explained by the model}. It's the variability \textbf{captured by the regression line}.
    
    
    \item \definition{Residual Sum of Squares (RSS)} (or error sum of squares)
    \begin{equation*}
        \text{RSS} = \displaystyle\sum_{i=1}^{n} \left(Y_i - \hat{Y}_i\right)^{2}
    \end{equation*}
    Measures the remaining \textbf{unexplained error}, how far off the predictions are from the actual values. This was explained on page \pageref{eq: RSS}.
    
    
    \item \definition{Total Sum of Squares (TSS)}
    \begin{equation}
        \text{TSS} = \displaystyle\sum_{i=1}^{n}\left(Y_{i} - \bar{Y}\right)^{2}
    \end{equation}
    Measures the \textbf{total variability} in the data. It's how much the actual values $Y_i$ vary around the mean $\bar{Y}$. In other words, how ``\emph{spread out}'' the data is.

    In Ordinary Least Squares (OLS) regression, we always have the following \definition{Fundamental Identity}:
    \begin{equation}
        \text{TSS} = \text{SSR} + \text{RSS}
    \end{equation}
    OLS finds $\hat{\beta}$ to \textbf{minimize RSS}, and it guarantees that the residuals\break $\mathbf{e} = Y - \hat{Y}$ are \textbf{orthogonal} to the fitted values. Because of this orthogonality, the squared norms satisfy the Pythagorean theorem:
    \begin{equation*}
        \left\| Y - \bar{Y} \right\|^{2} = \left\| \hat{Y} - \bar{Y} \right\|^{2} + \left\| Y - \hat{Y} \right\|^{2} \quad \Rightarrow \quad \text{TSS} = \text{SSR} + \text{RSS}
    \end{equation*}
\end{itemize}

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Coefficient of Determination}}
\end{flushleft}
The \definition{Coefficient of Determination} is \textbf{one of the most important metrics} to evaluate how well our linear regression model fits the data. It is defined as:
\begin{equation}\label{eq: coefficient of determination}
    R^{2} = \dfrac{
        \text{Explained Variation}
    }{
        \text{Total Variation}
    } =
    \dfrac{\text{SSR}}{\text{TSS}} =
    1 - \dfrac{\text{RSS}}{\text{TSS}}
\end{equation}
It tells us the \textbf{proportion} of the variance in $Y$ that is \textbf{explained by our regression model}.
\begin{itemize}
    \item[\textcolor{Green3}{\faIcon{check-circle}}] If our model predicts the values \textbf{perfectly}, then:
    \begin{equation*}
        \hat{Y}_i = Y_i \quad \Rightarrow \quad \text{RSS} = 0 \quad \Rightarrow \quad R^{2} = 1
    \end{equation*}

    \item[\textcolor{Orange3}{\faIcon{balance-scale}}] If our model does \textbf{not better than predicting the mean}, then:
    \begin{equation*}
        \hat{Y}_i = \bar{Y} \quad \Rightarrow \quad \text{SSR} = 0 \quad \Rightarrow \quad R^{2} = 0
    \end{equation*}

    \item[\textcolor{Red2}{\faIcon{times-circle}}] If our model is \textbf{worse than predicting the mean}, then:
    \begin{equation*}
        \text{RSS} > \text{TSS} \quad \Rightarrow \quad R^{2} < 0
    \end{equation*}
\end{itemize}
For example, if $\text{TSS} = 100$, and $\text{RSS} = 20$, then:
\begin{equation*}
    R^{2} = 1 - \dfrac{20}{100} = 0.80 \quad \Rightarrow \quad \text{Our model explains 80\% of the variation in } Y
\end{equation*}
$R^{2}$ always \textbf{increases} as we add \textbf{more predictors} (even useless ones), and for multiple regression, we often use Adjusted $R^{2}$ to penalize unnecessary complexity.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\textwidth]{img/linear-regression/model-evaluation.pdf}
    \caption{A side-by-side comparison of a Good Model vs. a Bad Model using the same dataset.}
    \label{fig: good vs bad model}
\end{figure}

\noindent
The coefficient of determination, $R^2$, is a widely used metric to assess model fit. However, it tends to increase with model complexity, even when additional predictors do not improve the model's true explanatory power, leading to overfitting. To address this, a more robust variant, the Adjusted $R^2$, was developed (see page \pageref{paragraph: Adjusted R2}). It is particularly useful in model selection, as it penalizes unnecessary complexity and provides a more reliable assessment of model performance.

\newpage

\begin{table}[!htp]
    \centering
    \begin{adjustbox}{width={\textwidth},totalheight={\textheight},keepaspectratio}
    \begin{tabular}{@{} l l p{10em} l @{}}
        \toprule
        \textbf{Metric} & \textbf{What it means} & \textbf{Good Model} & \textbf{Bad Model} \\
        \midrule
        \multirow{2}{*}{TSS}        & \multirow{2}{*}{Total variability in $Y$} & 3821.1 & 3821.1 \\ [.3em]
                                    &  & \multicolumn{2}{c}{Same for both, this is fixed by the data} \\
        \cmidrule{1-4}
        \multirow{2}{*}{RSS}        & \multirow{2}{*}{Unexplained error} & 325.96 & 3751.18 \\ [.3em]
                                    &  & Low, model fits well & High, model fits poorly \\
        \cmidrule{1-4}
        \multirow{2}{*}{SSR}        & \multirow{2}{*}{Explained variation} & 3495.13 & 69.92 \\ [.3em]
                                    &  & High, captures most of the structure & Very low \\
        \cmidrule{1-4}
        \multirow{2}{*}{$R^{2}$}    & \multirow{2}{*}{Proportion of explained variance} & 0.91 & 0.02 \\ [.3em]
                                    &  & 91\% explained & Only 2\% explained \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Model evaluation of Figure \ref{fig: good vs bad model}.}
\end{table}

\noindent
This illustrates how $R^{2}$ measures \textbf{how well ur model captures the true pattern in the data}.