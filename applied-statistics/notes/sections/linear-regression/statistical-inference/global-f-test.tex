\subsubsection{Global F-Test}\label{subsubsection: Global F-Test}

While the t-test checks if an individual coefficient (e.g., $\beta_1$) is significant, the F-test asks: ``\emph{does the \textbf{entire regression model} explain the data \textbf{better than just using the mean}?}''. In other words, do \textbf{any} of the predictors explain $Y$? Or are all the $\beta_j = 0$, meaning the model is useless?

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Hypotheses}}
\end{flushleft}
\begin{itemize}
    \item \textbf{Null Hypothesis} $H_0$:
    \begin{equation*}
        \beta_1 = \beta_2 = \dots = \beta_p = 0
    \end{equation*}
    No predictors matter, model has no explanatory power.

    \item \textbf{Alternative Hypothesis} $H_1$:
    \begin{equation*}
        \text{At least one } \beta_j \ne 0
    \end{equation*}
    At least one predictor helps explain $Y$.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{How is the F-Statistic computed?}}
\end{flushleft}
\begin{equation}
    F = \dfrac{
        \dfrac{\left(\text{TSS} - \text{RSS}\right)}{p}
    }{
        \dfrac{\text{RSS}}{\left(n - p - 1\right)}
    } = \dfrac{
        \text{Explained variance per predictor}
    }{
        \text{Unexplained variance per residual dof}
    }
\end{equation}
Where:
\begin{itemize}
    \item $p$ is the number of predictors
    \item $n$ is the number of observations
    \item TSS is the total sum of squares
    \item RSS is the residual sum of squares
\end{itemize}
We compare this F-statistic to an F-distribution with $p$ and $n-p-1$ degrees of freedom.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{What does it tell us?}}
\end{flushleft}
\begin{itemize}
    \item \hl{Large F, small p-value}: the model is \textbf{statistically significant}.
    \item \hl{Small F, large p-value}: the model doesn't explain the data better than a flat mean.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Red2}{\faIcon{question-circle} \textbf{Why use the Global F-Test?}}
\end{flushleft}
Because it answers: ``\emph{is this model \textbf{useful at all}, or should we just predict $Y$ using its average?}''. This is especially useful when we have \textbf{multiple predictors}, or we want to test the \textbf{entire model at once}.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\textwidth]{img/linear-regression/global-f-test.pdf}
    \captionsetup{singlelinecheck=off}
    \caption[]{A visual explanation of the Global F-Test.
    \begin{itemize}
        \item Black points: the actual observed $Y_i$ values
        \item Blue line: predictions from the \textbf{full regression model} $\left(\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i\right)$
        \item Red dashed line: prediction from the \textbf{null model}, simply the mean of $Y$, i.e., $\hat{Y}_i = \bar{Y}$
    \end{itemize}
    The \textbf{null model} (red line) says ``Forget $X$, just guess everyone's output is the average''. The \textbf{full model} (blue line) says ``Use $X$ to predict $Y$''. The Global F-Test checks ``does the blue line explain significantly more than the red one?''.
    \begin{equation*}
        F = \dfrac{\text{Improvement } \left(\text{Red } \rightarrow \text{ Blue}\right)}{\text{Leftover Error}}
    \end{equation*}
    If:
    \begin{itemize}
        \item Blue is \textbf{much closer} to the points than red $\Rightarrow$ large F $\Rightarrow$ \textbf{significant model}.
        \item Blue is \textbf{barely better} than red $\Rightarrow$ small F $\Rightarrow$ \textbf{not useful}.
    \end{itemize}}
\end{figure}