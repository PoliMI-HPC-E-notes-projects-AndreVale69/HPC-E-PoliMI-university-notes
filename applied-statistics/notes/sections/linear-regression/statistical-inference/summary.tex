\subsubsection{Summary}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Goal}}
\end{flushleft}
After estimating the regression line:
\begin{equation*}
    \hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X    
\end{equation*}
We want to answer:
\begin{itemize}
    \item Is this model \textbf{trustworthy}?
    \item Are the coefficients \textbf{significantly different from 0}?
    \item What's the \textbf{uncertainty} in our predictions?
\end{itemize}
To do that, we use \textbf{Statistical Inference}.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{1. Sampling Distributions \& the Central Limit Theorem (CLT)}}
\end{flushleft}
\begin{itemize}
    \item Our coefficients $\hat{\beta}_0, \hat{\beta}_1$ come from a \textbf{sample}
    \item If we collected different data, we'd get different values
    \item The CLT tells us:
    \begin{equation*}
        \hat{\beta}_j \sim \mathcal{N}(\beta_j, \text{Var}(\hat{\beta}_j)) \quad \text{(approximately)}
    \end{equation*}
    This normality enables confidence intervals and hypothesis testing.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{2. Standard Errors and Confidence Intervals}}
\end{flushleft}
\begin{itemize}
    \item The \textbf{standard error (SE)} measures how much $\hat{\beta}_j$ would vary across samples
    \item A \textbf{95\% confidence interval} for $\beta_1$ is:
    \begin{equation*}
        \hat{\beta}_1 \pm t_{n-2} \cdot \text{SE}\left(\hat{\beta}_1\right)
    \end{equation*}
    \item Interpretation: ``\emph{we're 95\% confident the true slope lies in this range.}''
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{3. t-Test for Individual Coefficients}}
\end{flushleft}
\begin{itemize}
    \item Tests whether a specific $\beta_j$ is \textbf{statistically significantly different from 0}
    \item Hypotheses:
    \begin{equation*}
        H_0: \beta_j = 0 \quad \text{vs} \quad H_1: \beta_j \ne 0
    \end{equation*}
    \item Test statistic:
    \begin{equation*}
        t = \frac{\hat{\beta}_j - 0}{\text{SE}\left(\hat{\beta}_j\right)}
    \end{equation*}
    \item Compare this to a \textbf{t-distribution} to compute the \textbf{p-value}
    \item[\textcolor{Green3}{\faIcon{check-circle}}] If the p-value is small $\Rightarrow$ \textbf{predictor matters}
    \item[\textcolor{Red2}{\faIcon{times-circle}}] If the p-value is large $\Rightarrow$ \textbf{no strong evidence}
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{4. Global F-Test (Model-Wide)}}
\end{flushleft}
\begin{itemize}
    \item Tests whether \textbf{any} of the predictors have a significant effect
    \item Hypotheses:
    \begin{equation*}
        H_0: \beta_1 = \beta_2 = \dots = \beta_p = 0 \quad \text{(model does nothing)}
    \end{equation*}
    \item F-statistic:
    \begin{equation*}
        F = \frac{(\text{TSS} - \text{RSS}) / p}{\text{RSS} / (n - p - 1)}
    \end{equation*}
    \item Compare to an \textbf{F-distribution} with $\left(p, n - p - 1\right)$ degrees of freedom
    \item[\textcolor{Green3}{\faIcon{check-circle}}] Small p-value $\Rightarrow$ the model is \textbf{useful}
    \item[\textcolor{Red2}{\faIcon{times-circle}}] Large p-value $\Rightarrow$ the model might not be better than guessing the mean
\end{itemize}

\highspace
\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l l l @{}}
        \toprule
        \textbf{Tool} & \textbf{Tests} & \textbf{Interpretation} \\
        \midrule
        \textbf{CLT}        & All coefficients & Allows inference via normal approximation \\ [.3em]
        \textbf{SE $+$ CI}  & Estimate accuracy & How much estimates vary \\ [.3em]
        \textbf{t-Test}     & Each coefficient & Is this predictor significant? \\ [.3em]
        \textbf{F-Test}     & Entire model & Is the model useful at all? \\
        \bottomrule
    \end{tabular}
\end{table}
