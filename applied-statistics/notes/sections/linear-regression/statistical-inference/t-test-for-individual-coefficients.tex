\subsubsection{t-Test for Individual Coefficients}\label{subsubsection: t-Test for Individual Coefficients}

\definition{t-Test for Individual Coefficients} is a \textbf{hypothesis test} to check whether an individual variable in our regression \textbf{is statistically significant}, i.e., whether it \textbf{truly affects the response variable} $Y$.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Why do we do this?}}
\end{flushleft}
We run a regression and get:
\begin{equation*}
    \hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X
\end{equation*}
But we want to know: ``\emph{is this slope $\hat{\beta}_1$ \textbf{actually meaningful}, or did we just get lucky with the data?}''. That's exactly what the \textbf{t-test} answers.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{How does it work?}}
\end{flushleft}
The core logic behind the t-test is to determine \textbf{whether there is sufficient evidence to conclude that} $\beta_1 \ne 0$ in the population. In other words, we need to establish whether the estimated slope is significantly different from zero.
\begin{enumerate}
    \item \important{Set up the hypotheses}.
    \begin{itemize}
        \item Null Hypothesis $H_0$: $\beta_1 = 0$ (no effect)
        \item Alternative Hypothesis $H_1$: $\beta_1 \ne 0$ (some effect)
    \end{itemize}


    \item \important{Compute the t-Statistic}. This tells us how many standard errors away is our slope from 0:
    \begin{equation}
        t = \dfrac{\hat{\beta}_1 - 0}{\text{SE}\left(\hat{\beta}_1\right)}
    \end{equation}
    It tells us \textbf{how far} our estimated slope $\hat{\beta}_1$ is from the null value (usually 0), in units of standard error.


    \item \important{Compare to t-Distribution}. Use a t-distribution with $n-2$ degrees of freedom. The \definition{t-distribution} looks like a \textbf{normal distribution}, but it has fatter tails. We use the \textbf{t-distribution instead of the normal distribution} because we are \textbf{estimating the standard deviation from the data} rather than using the true population standard deviation.
    
    Finally, we compute the p-value. The \definition{p-value} is the probability, \textbf{under the null hypothesis} $H_0$, of observing a t-statistic as extreme or more extreme than the one we got.
    \begin{equation}
        p = P\left(\left|T\right| > \left|t\right|\right) \quad \text{where } T \sim t_{n-2}
    \end{equation}
    This is calculated using the \textbf{cumulative distribution function (CDF)} of the t-distribution.
    
    and compute the p-value.
    \begin{itemize}
        \item If p-value $< 0.05$, reject $H_0$
        \item If p-value $> 0.05$, not significant
    \end{itemize}
\end{enumerate}