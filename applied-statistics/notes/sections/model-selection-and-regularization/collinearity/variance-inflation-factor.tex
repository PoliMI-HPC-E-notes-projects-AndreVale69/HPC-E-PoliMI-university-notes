\subsubsection{Variance Inflation Factor (VIF)}

\definition{Variance Inflation Factor (VIF)} measures \textbf{how much the variance} of a regression coefficient is \textbf{inflated due to multicollinearity}. It quantifies the severity of multicollinearity in an OLS regression.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{How is VIF defined?}}
\end{flushleft}
For a coefficient $\hat{\beta}_{j}$, the VIF is:
\begin{equation}
    \text{VIF}_j = \dfrac{1}{1 - R_j^2}
\end{equation}
Where $R_j^2$ is the \textbf{coefficient of determination} when \textbf{regressing $X_j$ on all other predictors}.

\highspace
Usually in regression, we do this:
\begin{equation*}
    Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \varepsilon
\end{equation*}
But for VIP, we switch things up. \textbf{Instead of using $X_j$ to predict $Y$}, we do:
\begin{equation*}
    X_j = \gamma_0 + \gamma_1 X_1 + \gamma_2 X_2 + \dots + \gamma_{j-1} X_{j-1} + \gamma_{j+1} X_{j+1} + \dots + \gamma_p X_p + \eta
\end{equation*}
So we make $X_j$ the dependent variable, and we use all other $X_k$ (except $X_j$) as independent variables. Then we compute the $R^2$ of this regression.
\begin{itemize}
    \item If $R_j^2 = 0$: $X_j$ is independent, then no multicollinearity and $\text{VIF}_j = 1$.
    \item If $R_j^2 = 0.9$: 90\% of $X_j$'s variance is explained by others, then $\text{VIF}_j = \dfrac{1}{1 - 0.9} = 10$, danger!
\end{itemize}

\highspace
\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l l @{}}
        \toprule
        VIF value & Interpretation \\
        \midrule
        $\text{VIF} = 1$     & \textcolor{Green3}{\faIcon{check-circle}} No correlation with other variables.           \\ [.5em]
        $1 < \text{VIF} < 5$ & \textcolor{Orange3}{\faIcon{balance-scale}} Moderate correlation, usually okay.            \\ [.5em]
        $\text{VIF} > 5$     & \textcolor{Red2}{\faIcon{exclamation-triangle}} High correlation, potential multicollinearity. \\ [.5em]
        $\text{VIF} > 10$    & \textcolor{Red2}{\faIcon{skull-crossbones}} Very high correlation, serious problem.        \\ [.5em]
        \bottomrule
    \end{tabular}
    \caption{Interpretation of the VIF.}
\end{table}

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{Why it works?}}
\end{flushleft}
The variance of the OLS estimate $\hat{\beta}_j$ is:
\begin{equation*}
    \text{Var}(\hat{\beta}_j) = \frac{\sigma^2}{(1 - R_j^2) \cdot S_{jj}}
\end{equation*}
Where:
\begin{itemize}
    \item $\sigma^2$ is the noise variance.
    \item $S_{jj}$ is the variance of $X_j$ itself (scaled sum of squares).
    \item $R_j^2$ is how well $X_j$ is explained by the other variables.
\end{itemize}
\hl{If $R_j^2$ is high ($R_j^2 \to 1$), then $1 - R_j^2$ is small (denominator $\to 0$)}. This is the \textbf{mechanism} behind multicollinearity, the more predictable $X_j$ is from the others, the more \textbf{uncertain} our model is about how much $X_j$ actually contributes to predicting $Y$.

\highspace
So Variance Inflation Factor (VIF) is a \textbf{multiplier}, it tells us \textbf{how much larger the variance of $\hat{\beta}_j$ is due to collinearity}. For example, if $R_j^2 = 0.95$, then $\text{VIF}_j = \frac{1}{0.05} = 20$, and the variance of $\hat{\beta}_j$ is $20\times$ worse than it would be with independent variables.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\textwidth]{img/model-selection-and-regularization/vif.pdf}
    \captionsetup{singlelinecheck=off}
    \caption[]{Top Plot: Regression Line. The \textbf{line fits the data well visually}, it looks like a strong relationship. Indeed, the $R^2 = 0.903$: 90\% of the variability in $X_2$ is explained by $X_1$. But this is \textbf{not a good thing in this context}.
    
    \highspace
    Bottom Plot: VIF Curve. The correlation of 0.95 (marked in red) leads to $\text{VIF} \approx 15$. Even though the fit looks great, the \textbf{usefulness of} $X_2$ in a regression model with $X_1$ is highly questionable.
    
    \highspace
    A regression line might \textbf{look clean and convincing}, but if the predictor is \textbf{highly collinear}, our model is \textbf{mathematically unstable}. The \textbf{VIF reveals what the plot hides}: danger beneath the surface.}
\end{figure}