\subsubsection{Best Subset Selection}\label{subsubsection: Best Subset Selection}

The \definition{Best Subset Selection} is a method to find the combination of predictors that produces the best-performing linear regression model. Among all possible subsets of predictors, we \textbf{search for the one that minimizes prediction error} (or maximizes Adjusted $R^2$, AIC, BIC, etc.).

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{tools} \textbf{How it works}}
\end{flushleft}
Suppose we have $p$ predictors: $X_1, X_2, \dots, X_p$:
\begin{enumerate}
    \item For each $k = 0, 1, \dots, p$:
    \begin{itemize}
        \item Consider \textbf{all possible models} that contain \textbf{exactly $k$ predictors}.
        \item Fit all $\binom{p}{k}$\footnote{%
            \definition{Binomial Coefficient} gives the number of ways to choose $k$ elements from a set of $p$ elements \textbf{without regard to order}.
        } combinations of those predictors. Where $p$ is the total number of available predictors, and $k$ is the number of predictors we want to include in the model. In other words, is the number of different models we can build using \textbf{exactly} $k$ of the $p$ predictors.
    \end{itemize}

    \item Among all models of size $k$, choose the one with the \textbf{lowest training RSS}\footnote{%
        RSS refers to the Residual Sum of Squares (page \pageref{eq: RSS}).
    } (or highest adjusted $R^2$). The \emph{lowest training RSS} is achieved by the model with all $p$ predictors, and it is:
    \begin{equation*}
        \min_{k=1,\dots,p} \left( \min_{\text{model with }k\text{ predictors}} \text{RSS} \right) = \text{RSS of full model}
    \end{equation*}

    \item Compare the \textbf{best models of each size} $k$ using a criterion: Validation Set (page \pageref{paragraph: Validation Set}), Cross-Validation (page \pageref{paragraph: Cross-Validation}), Adjusted $R^{2}$ (page \pageref{paragraph: Adjusted R2}), AIC / BIC (page \pageref{paragraph: AIC and BIC}), Mallows' $C_p$ (page \pageref{paragraph: Mallows' Cp}).
\end{enumerate}

\begin{table}[!htp]
    \centering
    \begin{tabular}{@{} l l @{}}
        \toprule
        Step & Action \\
        \midrule
        1 & Try all possible subsets of predictors. \\ [.3em]
        2 & Find the best model for each number of predictors. \\ [.3em]
        3 & Choose the best overall model based on a criterion. \\
        \bottomrule
    \end{tabular}
\end{table}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{When to use it}}
\end{flushleft}
\begin{itemize}
    \item When $p$ is small (typically $< 20$).
    \item When interpretability matters.
    \item When we want to explore all possibilities.
\end{itemize}

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon{check-circle} \textbf{Advantages}}
\end{flushleft}
\begin{itemize}[label=\textcolor{Green3}{\faIcon{check}}]
    \item \textbf{Exhaustive}: finds the optimal model \textbf{for each size}.
    \item Easy to \textbf{understand and explain}.
    \item Produces interpretable models.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Red2}{\faIcon{times-circle} \textbf{Disadvantages}}
\end{flushleft}
\begin{itemize}[label=\textcolor{Red2}{\faIcon{times}}]
    \item Computationally \textbf{expensive}: $2^p$ models to fit (e.g., 1,024 if $p = 10$, 1 million if $p = 20$).
    \item Not feasible for \textbf{large $p$}.
\end{itemize}

\highspace
\begin{examplebox}[: Best Subset Selection]
    We want to predict exam score using these predictors:
    \begin{itemize}
        \item $X1$: study hours.
        \item $X2$: number of coffee cups.
        \item $X3$: hours of sleep.
        \item $X4$: prior GPA.
    \end{itemize}
    So we have $p = 4$ predictors. Our \emph{\textbf{goal}} is to find \textbf{which combination} of these predictors gives the \textbf{best linear model} for predicting score. Not necessarily all 4, maybe only $X1$ and $X4$ are enough.

    \highspace
    \textcolor{Green3}{\faIcon{question-circle} \textbf{What does best subset do?}} It tries \textbf{every possible combination} of predictors, and compares the models. Let's list them:
    \begin{enumerate}
        \item Try 1-variable models:
        \begin{itemize}
            \item Model A: $Y = \beta_0 + \beta_1 X_1$
            \item Model B: $Y = \beta_0 + \beta_2 X_2$
            \item Model C: $Y = \beta_0 + \beta_3 X_3$
            \item Model D: $Y = \beta_0 + \beta_4 X_4$
        \end{itemize}
        For each model fit it on training data, then compute a score that tells how good it is (AIC / BIC, etc.). Finally, among these 4 one-variable models, we pick the best one.

        \item Try 2-variable models:
        \begin{itemize}
            \item Model A: $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2$
            \item Model B: $Y = \beta_0 + \beta_1 X_1 + \beta_3 X_3$
            \item Model C: $Y = \beta_0 + \beta_1 X_1 + \beta_4 X_4$
            \item Model D: $Y = \beta_0 + \beta_2 X_2 + \beta_3 X_3$
            \item Model E: $Y = \beta_0 + \beta_2 X_2 + \beta_4 X_4$
            \item Model F: $Y = \beta_0 + \beta_3 X_3 + \beta_4 X_4$
        \end{itemize}
        And we pick the best one.
        \item Try 3-variable models:
        \begin{itemize}
            \item Model A: $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3$
            \item Model B: $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_4 X_4$
            \item Model C: $Y = \beta_0 + \beta_1 X_1 + \beta_3 X_3 + \beta_4 X_4$
            \item Model D: $Y = \beta_0 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4$
        \end{itemize}
        Then the best one.
        \item Try all 4 predictors (only one): $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4$
    \end{enumerate}
    With 4 predictors, there are $2^4 = 16$ possible subsets, then 16 models to try. At the end, we \textbf{compare the best model} of each size, and then pick the one that gives the \textbf{lowest estimated test error}.
\end{examplebox}