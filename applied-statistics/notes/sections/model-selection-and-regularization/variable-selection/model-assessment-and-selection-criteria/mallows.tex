\paragraph{\texorpdfstring{Mallows' $C_p$}{Mallows' Cp}}

\definition{Mallows' $C_p$} is a metric designed to estimate \textbf{how much error} our model will make on \textbf{new data}, while \textbf{penalizing complexity}, just like AIC and BIC. It was developed specifically for \textbf{linear models} and works especially well in \textbf{Best Subset Selection} (page \pageref{subsubsection: Best Subset Selection}).

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{square-root-alt} \textbf{Formula}}
\end{flushleft}
For a linear regression model with $d$ predictors and residual sum of squares $\text{RSS}_d$, Mallows' $C_p$ is:
\begin{equation}
    C_p = \dfrac{1}{\hat{\sigma}^2} \left( \text{RSS}_d + 2d \cdot \hat{\sigma}^2 \right)
\end{equation}
Where:
\begin{itemize}
    \item $\text{RSS}_d$: Residual sum of squares for the model with $d$ predictors.
    \item $\hat{\sigma}^2$: Estimate of the \textbf{irreducible error} (often from the full model).
\end{itemize}
We can use a \textbf{simplified version} when working with \textbf{linear regression models} or when we want a \textbf{quick comparison of different subset models}:
\begin{equation*}
    C_p = \dfrac{\text{RSS}_d}{\hat{\sigma}^2} - \left(n - 2d\right)
\end{equation*}
But be careful because this formula \textbf{depends on a good estimate of $\hat{\sigma}^2$}. If $\hat{\sigma}^2$ is \textbf{underestimated}, $C_p$ will \textbf{favor too complex models} (under-penalize complexity). If overestimated, it might underfit. So, use the simplified formula when doing linear regression subset selection, and when we have a good estimate of the model's noise variance from the full model.

\highspace
However, like AIC, it tries to \textbf{balance fit and complexity}. If our model is good (low bias, low variance), then $C_p approx d$ (the number of predictors).
\begin{itemize}
    \item If $C_p > d$, our model is likely \textbf{missing important variables}.
    \item If $C_p < d$, our model may be \textbf{overfitting}.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{How do we use it?}}
\end{flushleft}
Compute $C_p$ for each candidate model (especially in subset selection). Then, \textbf{choose the model where $C_p$ is smallest}, and ideally \hl{\textbf{close to} $d$}.