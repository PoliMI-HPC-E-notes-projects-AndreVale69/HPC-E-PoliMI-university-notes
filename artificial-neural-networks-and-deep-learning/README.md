# (2025/2026) Artificial Neural Networks and Deep Learning

The notes are taken from the books required for the course: 

- _Ian Goodfellow, Yoshua Bengio, and Aaron Courville_, **Deep Learning**, Editore: MIT Press, ISBN: 978-0262035613, http://www.deeplearningbook.org/.
- Course slides.

You can view/download the PDF [here](notes/artificial-neural-networks-and-deep-learning.pdf). In the [notes folder](notes/), you can also see the source code.

For any issue, [use the appropriate section](https://github.com/PoliMI-HPC-E-notes-projects-AndreVale69/HPC-E-PoliMI-university-notes/issues).

## Course Syllabus

According to the [official course syllabus](https://www11.ceda.polimi.it/schedaincarico/schedaincarico/controller/scheda_pubblica/SchedaPublic.do?&evn_default=evento&c_classe=863895&__pj0=0&__pj1=8923b74f46a75e8fa2d66989cb859069):

1. From the Perceptron to Neural Networks and the Feedforward architecture
2. Backpropagation and Neural Networks training algorithms, e.g., Adagrad, adam, etc.
3. Best practices in neural network training: overfitting and cross-validation, stopping criteria, weight decay, dropout, data resampling and augmentation.
4. Image Classification problem  and Neural Networks
5. Recurrent Neural Networks and other relevant architectures such as (Sparse) Neural Autoencoders
6. Theoretical results: Neural Networks as universal approximation tools, vanishing and exploding gradients, etc.
7. Introduction to the Deep Learning paradigm and its main differences with respect to classical Machine Learning
8. Convolutional Neural Networks (CNN) architecture
9. The breakthrough of CNN and their interpretation
10. CNN training and data-augmentation
11. Structural learning, Long-Short Term Memories, and their applications to text and speech
12. Autoencoders and data embedding, word2vec, variational autoencoders
13. Transfer Learning for pre-trained Deep models
14. Extended models including Fully Convolutional CNN, networks for image segmentation (U-net) and object detection (e.g., R-CNN, YOLO )
15. Generative Models (e.g., Generative Adversarial Networks)