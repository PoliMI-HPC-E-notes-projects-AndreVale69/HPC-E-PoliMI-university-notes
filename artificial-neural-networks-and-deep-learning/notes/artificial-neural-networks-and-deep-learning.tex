\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}			    % \chapter package
\usepackage[english]{babel}
\usepackage[english]{isodate}  		    % date format
\usepackage{graphicx}				    % manage images
\usepackage{amsfonts}
\usepackage{booktabs}				    % high quality tables
\usepackage{amsmath}				    % math package
\usepackage{amssymb}				    % another math package (e.g. \nexists)
\usepackage{bm}                         % bold math symbols
\usepackage{mathtools}				    % emphasize equations
\usepackage{stmaryrd} 				    % '\llbracket' and '\rrbracket'
\usepackage{amsthm}					    % better theorems
\usepackage{enumitem}				    % manage list
\usepackage{pifont}					    % nice itemize
\usepackage{cancel}					    % cancel math equations
\usepackage{caption}				    % custom caption
\usepackage[]{mdframed}				    % box text
\usepackage{multirow}				    % more lines in a table
\usepackage{textcomp, gensymb}		    % degree symbol
\usepackage[x11names]{xcolor}		    % RGB color
\usepackage[many]{tcolorbox}		    % colorful box
\usepackage{multicol}				    % more rows in a table (used for the lists)
\usepackage{listings}
\usepackage{url}
\usepackage{qrcode}
\usepackage{fontawesome5}
\usepackage{ragged2e}
\usepackage{cite}                       % references
\usepackage{imakeidx}                   % index
\makeindex[program=makeindex, columns=1,
           title=Index, 
           intoc,
           options={-s index-style.ist}]
\usepackage{fancyhdr}
\usepackage{soul}                       % highlight text (as a highlighter)
\usepackage{adjustbox}                  % avoid table overfull
\usepackage{pgf}                        % insert pgf images
\usepackage{gensymb}                    % for textdegree
\usepackage{tikz}
\usetikzlibrary{trees,calc}


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}


% thanks Mico: https://tex.stackexchange.com/a/60218/312896
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
            {-2.5ex\@plus -1ex \@minus -.25ex}%
            {1.25ex \@plus .25ex}%
            {\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4} % how many sectioning levels to assign numbers to
\setcounter{tocdepth}{4}    % how many sectioning levels to show in ToC


% draw a frame around given text
\newcommand{\framedtext}[1]{%
	\par%
	\noindent\fbox{%
		\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}{#1}%
	}%
}


% table of content links
\usepackage{xcolor}
\usepackage[linkcolor=black, citecolor=blue, urlcolor=cyan]{hyperref} % hypertexnames=false
\hypersetup{
	colorlinks=true
}


\newtheorem{theorem}{\textcolor{Red3}{\underline{Theorem}}}
\renewcommand{\qedsymbol}{QED}
\newcommand{\dquotes}[1]{``#1''}
\newcommand{\important}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\longline}{\noindent\rule{\textwidth}{0.4pt}}
\newcommand{\circledtext}[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt}{#1}}}}
\newcommand{\definition}[1]{\textcolor{Red3}{\textbf{#1}}\index{#1}}
\newcommand{\example}[1]{\textcolor{Green4}{\textbf{#1}}}
\newcommand{\highspace}{\vspace{1.2em}\noindent}
% I never remember every icon, so I use custom commands to do this
\newcommand{\speedIcon}{tachometer-alt}
\newcommand{\definitionWithSpecificIndex}[3]{\textcolor{Red3}{\textbf{#1}}\index{#2}\index{#3}}
\newcommand{\hqlabel}[2]{\label{#1}\hypertarget{#1}{#2}}
\newcommand{\hqpageref}[1]{\hyperlink{#1}{\hypergetpageref{#1}}}
\newcommand{\naive}{naïve }
\newcommand{\Naive}{Naïve }
\newcommand{\appliedStatisticsRef}[1]{More resources about #1 can be found in the notes for the Applied Statistics course:
\begin{center}
    \qrcode{https://polimi-hpc-e-notes-projects-andrevale69.github.io/HPC-E-PoliMI-university-notes/applied-statistics/notes/applied-statistics.pdf}
\end{center}}
\newcommand{\version}{v0.2.0}

% \includeonly{
%     sections/from-perceptrons-to-feed-forward-neural-networks/historical-context,
%     sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/who-invented-it,
%     sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/mathematical-model-and-logical-operations,
%     sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/hebbian-learning-rule,
%     sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/perceptron-as-linear-classifier,
%     sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/boolean-operators-and-linear-separability,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/architecture,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/linear,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/sigmoid,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/tanh,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/regression,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/binary-classification,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/multi-class-classification,
%     sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/neural-networks-as-universal-approximators,
%     sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/learning-and-optimization,
%     sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/supervised-learning-and-training-dataset,
%     sections/bibliography-and-index
% }


\begin{document}
    \newcounter{definition}[section]
    \newcounter{example}[section]
    \newcounter{takeaways}[section]
    
    \newtcolorbox[use counter = definition]{definitionbox}[1][]{%
        breakable,
        enhanced,
        colback=red!5!white,
        colframe=red!75!black,
        fonttitle=\bfseries,
        title={Definition \thetcbcounter #1} %
    }
    
    \newtcolorbox[use counter = example]{examplebox}[1][]{%
        breakable,
        enhanced,
        colback=Green4!5!white,
        colframe=Green4!75!black,
        fonttitle=\bfseries,
        title={Example \thetcbcounter #1} %
    }

    \newtcolorbox[use counter = takeaways]{takeawaysbox}[1][]{%
        breakable,
        enhanced,
        colback=Green3!5!white,
        colframe=Green3!75!black,
        fonttitle=\bfseries,
        title={Key Takeaways#1} %
    }

    \newtcolorbox[]{remarkbox}[1][]{%
        breakable,
        enhanced,
        colback=DarkOrange3!5!white,
        colframe=DarkOrange3!75!black,
        fonttitle=\bfseries,
        title={Remark#1} %
    }

    \newtcolorbox[]{deepeningbox}[1][]{%
        breakable,
        enhanced,
        colback=DarkOrange3!5!white,
        colframe=DarkOrange3!75!black,
        fonttitle=\bfseries,
        title={Deepening#1} %
    }
	
    %%%%%%%%%%%%%%%
    % Notes cover %
    %%%%%%%%%%%%%%%
    \include{sections/notes-cover}

    %%%%%%%%%%%
    % Preface %
    %%%%%%%%%%%
    \include{sections/preface}

    %%%%%%%%%%%%%%%%%%%%%
    % Table of contents %
    %%%%%%%%%%%%%%%%%%%%%
    \tableofcontents
    \newpage

    %%%%%%%%%%%%%%%%%%%
    % Fancy pagestyle %
    %%%%%%%%%%%%%%%%%%%
    \pagestyle{fancy}
    \fancyhead{} % clear all header fields
    \fancyhead[R]{\nouppercase{\leftmark\hfill\rightmark}}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Introduction to Deep Learning %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-foundations}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/machine-learning-paradigms}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/supervised-learning}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/unsupervised-learning}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/reinforcement-learning}
    \include{sections/introduction-to-deep-learning/towards-deep-learning}
    \include{sections/introduction-to-deep-learning/modern-pattern-recognition-pre-dl}
    \include{sections/introduction-to-deep-learning/what-is-deep-learning-after-all}
    \include{sections/introduction-to-deep-learning/whats-behind-deep-learning}
    \include{sections/introduction-to-deep-learning/summary}
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % From Perceptrons to Feed-Forward Neural Networks (FNNs) %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/historical-context}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/who-invented-it}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/mathematical-model-and-logical-operations}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/hebbian-learning-rule}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/perceptron-as-linear-classifier}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/boolean-operators-and-linear-separability}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/architecture}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/linear}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/sigmoid}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/tanh}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/regression}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/binary-classification}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/multi-class-classification}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/neural-networks-as-universal-approximators}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/learning-and-optimization}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/supervised-learning-and-training-dataset}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/error-minimization-and-loss-function}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/gradient-descent-basics}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/backpropagation-conceptual-introduction}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/maximum-likelihood-estimation/maximum-likelihood-estimation}

    %%%%%%%%%%%%%%%%%%%%%%%%%%
    % Bibliography and index %
    %%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/bibliography-and-index}
\end{document}