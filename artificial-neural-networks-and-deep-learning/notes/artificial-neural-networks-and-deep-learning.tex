\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}			    % \chapter package
\usepackage[english]{babel}
\usepackage[english]{isodate}  		    % date format
\usepackage{graphicx}				    % manage images
\usepackage{amsfonts}
\usepackage{booktabs}				    % high quality tables
\usepackage{amsmath}				    % math package
\usepackage{amssymb}				    % another math package (e.g. \nexists)
\usepackage{bm}                         % bold math symbols
\usepackage{mathtools}				    % emphasize equations
\usepackage{stmaryrd} 				    % '\llbracket' and '\rrbracket'
\usepackage{amsthm}					    % better theorems
\usepackage{enumitem}				    % manage list
\usepackage{pifont}					    % nice itemize
\usepackage{cancel}					    % cancel math equations
\usepackage{caption}				    % custom caption
\usepackage[]{mdframed}				    % box text
\usepackage{multirow}				    % more lines in a table
\usepackage{textcomp, gensymb}		    % degree symbol
\usepackage[x11names]{xcolor}		    % RGB color
\usepackage[many]{tcolorbox}		    % colorful box
\usepackage{multicol}				    % more rows in a table (used for the lists)
\usepackage{listings}
\usepackage{url}
\usepackage{qrcode}
\usepackage{fontawesome5}
\usepackage{ragged2e}
\usepackage{cite}                       % references
\usepackage{imakeidx}                   % index
\makeindex[program=makeindex, columns=1,
           title=Index, 
           intoc,
           options={-s index-style.ist}]
\usepackage{fancyhdr}
\usepackage{soul}                       % highlight text (as a highlighter)
\usepackage{adjustbox}                  % avoid table overfull
\usepackage{pgf}                        % insert pgf images
\usepackage{gensymb}                    % for textdegree
\usepackage{tikz}
\usetikzlibrary{trees,calc,positioning,fit,arrows.meta,matrix}


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{whiteBackcolour}{rgb}{255,255,255}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstdefinestyle{pseudocode-style}{
	backgroundcolor=\color{whiteBackcolour},
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,
	breaklines=true,
	captionpos=b,
	keepspaces=true,
	numbers=left,
	numbersep=5pt,
	showspaces=false,
	showstringspaces=false,
	showtabs=false,
	tabsize=2,
    mathescape,
    frame=lines
}

\lstdefinelanguage{pseudo-code}{
	keywords={while, do, for, if, and, then, each, not},
	keywordstyle=\color{Red2}\bfseries,
	ndkeywords={},
	ndkeywordstyle=\color{darkgray}\bfseries,
	identifierstyle=\color{black},
	sensitive=false,
	comment=[l]{//},
	morecomment=[s]{/*}{*/},
	commentstyle=\color{codegreen}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	morestring=[b]',
	morestring=[b]"
}

\lstset{
	language=pseudo-code,
	backgroundcolor=\color{lightgray},
	extendedchars=true,
	basicstyle=\footnotesize\ttfamily,
	showstringspaces=false,
	showspaces=false,
	numbers=left,
	numberstyle=\footnotesize,
	numbersep=9pt,
	tabsize=2,
	breaklines=true,
	showtabs=false,
	captionpos=b,
    % increase new lines spacing in lstlisting
    lineskip={.2em}
}

\lstset{style=mystyle}


% thanks Mico: https://tex.stackexchange.com/a/60218/312896
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
            {-2.5ex\@plus -1ex \@minus -.25ex}%
            {1.25ex \@plus .25ex}%
            {\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4} % how many sectioning levels to assign numbers to
\setcounter{tocdepth}{4}    % how many sectioning levels to show in ToC


% draw a frame around given text
\newcommand{\framedtext}[1]{%
	\par%
	\noindent\fbox{%
		\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}{#1}%
	}%
}


% table of content links
\usepackage{xcolor}
\usepackage[linkcolor=black, citecolor=blue, urlcolor=cyan]{hyperref} % hypertexnames=false
\hypersetup{
	colorlinks=true
}


\newtheorem{theorem}{\textcolor{Red3}{\underline{Theorem}}}
\renewcommand{\qedsymbol}{QED}
\newcommand{\dquotes}[1]{``#1''}
\newcommand{\important}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\longline}{\noindent\rule{\textwidth}{0.4pt}}
\newcommand{\circledtext}[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt}{#1}}}}
\newcommand{\definition}[1]{\textcolor{Red3}{\textbf{#1}}\index{#1}}
\newcommand{\example}[1]{\textcolor{Green4}{\textbf{#1}}}
\newcommand{\highspace}{\vspace{1.2em}\noindent}
% I never remember every icon, so I use custom commands to do this
\newcommand{\speedIcon}{tachometer-alt}
\newcommand{\definitionWithSpecificIndex}[3]{\textcolor{Red3}{\textbf{#1}}\index{#2}\index{#3}}
\newcommand{\hqlabel}[2]{\label{#1}\hypertarget{#1}{#2}}
\newcommand{\hqpageref}[1]{\hyperlink{#1}{\hypergetpageref{#1}}}
\newcommand{\naive}{naïve }
\newcommand{\Naive}{Naïve }
\newcommand{\appliedStatisticsRef}[1]{More resources about #1 can be found in the notes for the Applied Statistics course:
\begin{center}
    \qrcode{https://polimi-hpc-e-notes-projects-andrevale69.github.io/HPC-E-PoliMI-university-notes/applied-statistics/notes/applied-statistics.pdf}
\end{center}}
\newcommand{\version}{v0.4.0}

% \includeonly{
%     sections/recurrent-neural-networks/recurrent-neural-networks,
%     sections/recurrent-neural-networks/sequence-modeling,
%     sections/recurrent-neural-networks/memoryless-models/autoregressive,
%     sections/recurrent-neural-networks/memoryless-models/feed-forward-extensions-time-delay-neural-networks,
%     sections/recurrent-neural-networks/models-with-memory/hidden-state-dynamics-and-outputs,
%     sections/recurrent-neural-networks/models-with-memory/linear-dynamical-systems-kalman-filter,
%     sections/recurrent-neural-networks/models-with-memory/hidden-markov-models,
%     sections/recurrent-neural-networks/models-with-memory/comparison-to-deterministic-recurrent-systems,
%     sections/recurrent-neural-networks/definition/what-is-a-rnn,
%     sections/recurrent-neural-networks/definition/nonlinear-update-equations-with-weights,
%     sections/recurrent-neural-networks/definition/universal-computation-capability,
%     sections/bibliography-and-index
% }


\begin{document}
    \newcounter{definition}[section]
    \newcounter{example}[section]
    \newcounter{takeaways}[section]
    
    \newtcolorbox[use counter = definition]{definitionbox}[1][]{%
        breakable,
        enhanced,
        colback=red!5!white,
        colframe=red!75!black,
        fonttitle=\bfseries,
        title={Definition \thetcbcounter #1} %
    }
    
    \newtcolorbox[use counter = example]{examplebox}[1][]{%
        breakable,
        enhanced,
        colback=Green4!5!white,
        colframe=Green4!75!black,
        fonttitle=\bfseries,
        title={Example \thetcbcounter #1} %
    }

    \newtcolorbox[use counter = takeaways]{takeawaysbox}[1][]{%
        breakable,
        enhanced,
        colback=Green3!5!white,
        colframe=Green3!75!black,
        fonttitle=\bfseries,
        title={Key Takeaways#1} %
    }

    \newtcolorbox[]{remarkbox}[1][]{%
        breakable,
        enhanced,
        colback=DarkOrange3!5!white,
        colframe=DarkOrange3!75!black,
        fonttitle=\bfseries,
        title={Remark#1} %
    }

    \newtcolorbox[]{deepeningbox}[1][]{%
        breakable,
        enhanced,
        colback=DarkOrange3!5!white,
        colframe=DarkOrange3!75!black,
        fonttitle=\bfseries,
        title={Deepening#1} %
    }
	
    %%%%%%%%%%%%%%%
    % Notes cover %
    %%%%%%%%%%%%%%%
    \include{sections/notes-cover}

    %%%%%%%%%%%
    % Preface %
    %%%%%%%%%%%
    \include{sections/preface}

    %%%%%%%%%%%%%%%%%%%%%
    % Table of contents %
    %%%%%%%%%%%%%%%%%%%%%
    \tableofcontents
    \newpage

    %%%%%%%%%%%%%%%%%%%
    % Fancy pagestyle %
    %%%%%%%%%%%%%%%%%%%
    \pagestyle{fancy}
    \fancyhead{} % clear all header fields
    \fancyhead[R]{\nouppercase{\leftmark\hfill\rightmark}}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Introduction to Deep Learning %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-foundations}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/machine-learning-paradigms}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/supervised-learning}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/unsupervised-learning}
    \include{sections/introduction-to-deep-learning/machine-learning-foundation/machine-learning-paradigms/reinforcement-learning}
    \include{sections/introduction-to-deep-learning/towards-deep-learning}
    \include{sections/introduction-to-deep-learning/modern-pattern-recognition-pre-dl}
    \include{sections/introduction-to-deep-learning/what-is-deep-learning-after-all}
    \include{sections/introduction-to-deep-learning/whats-behind-deep-learning}
    \include{sections/introduction-to-deep-learning/summary}
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % From Perceptrons to Feed-Forward Neural Networks (FNNs) %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/historical-context}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/who-invented-it}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/mathematical-model-and-logical-operations}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/hebbian-learning-rule}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/perceptron-as-linear-classifier}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/the-perceptron/boolean-operators-and-linear-separability}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/architecture}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/linear}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/sigmoid}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/activation-functions/tanh}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/regression}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/binary-classification}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/output-layer/multi-class-classification}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/feed-forward-neural-networks-fnns/neural-networks-as-universal-approximators}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/learning-and-optimization}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/supervised-learning-and-training-dataset}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/error-minimization-and-loss-function}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/gradient-descent-basics}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/learning-and-optimization/backpropagation-conceptual-introduction}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/maximum-likelihood-estimation}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/perceptron-learning-algorithm}
    \include{sections/from-perceptrons-to-feed-forward-neural-networks/summary}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Neural Networks and Overfitting %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/neural-networks-training-and-overfitting/universal-approximation-theorem}
    \include{sections/neural-networks-training-and-overfitting/model-complexity}
    \include{sections/neural-networks-training-and-overfitting/measuring-generalization}
    \include{sections/neural-networks-training-and-overfitting/terminology-clarifications}
    \include{sections/neural-networks-training-and-overfitting/cross-validation-techniques/hold-out-validation}
    \include{sections/neural-networks-training-and-overfitting/cross-validation-techniques/leave-one-out-cross-validation}
    \include{sections/neural-networks-training-and-overfitting/cross-validation-techniques/k-fold-cross-validation}
    \include{sections/neural-networks-training-and-overfitting/cross-validation-techniques/nested-cross-validation}
    \include{sections/neural-networks-training-and-overfitting/preventing-overfitting/preventing-overfitting}
    \include{sections/neural-networks-training-and-overfitting/preventing-overfitting/early-stopping}
    \include{sections/neural-networks-training-and-overfitting/preventing-overfitting/hyperparameter-tuning}
    \include{sections/neural-networks-training-and-overfitting/preventing-overfitting/weight-decay-l2-regularization}
    \include{sections/neural-networks-training-and-overfitting/preventing-overfitting/dropout-stochastic-regularization}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/tips-and-tricks}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/activation-function-saturation}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/relu-and-variants}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/weight-initialization}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/batch-normalization}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/mini-batch-training}
    \include{sections/neural-networks-training-and-overfitting/tips-and-tricks/learning-rate-scheduling}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Recurrent Neural Networks (RNNs) %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/recurrent-neural-networks/recurrent-neural-networks}
    \include{sections/recurrent-neural-networks/sequence-modeling}
    \include{sections/recurrent-neural-networks/memoryless-models/autoregressive}
    \include{sections/recurrent-neural-networks/memoryless-models/feed-forward-extensions-time-delay-neural-networks}
    \include{sections/recurrent-neural-networks/models-with-memory/hidden-state-dynamics-and-outputs}
    \include{sections/recurrent-neural-networks/models-with-memory/linear-dynamical-systems-kalman-filter}
    \include{sections/recurrent-neural-networks/models-with-memory/hidden-markov-models}
    \include{sections/recurrent-neural-networks/models-with-memory/comparison-to-deterministic-recurrent-systems}
    \include{sections/recurrent-neural-networks/definition/what-is-a-rnn}
    \include{sections/recurrent-neural-networks/definition/nonlinear-update-equations-with-weights}
    \include{sections/recurrent-neural-networks/definition/universal-computation-capability}

    %%%%%%%%%%%%%%%%%%%%%%%%%%
    % Bibliography and index %
    %%%%%%%%%%%%%%%%%%%%%%%%%%
    \include{sections/bibliography-and-index}
\end{document}