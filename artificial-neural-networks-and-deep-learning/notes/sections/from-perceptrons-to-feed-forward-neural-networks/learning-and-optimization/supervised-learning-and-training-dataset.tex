\subsubsection{Supervised Learning and Training Dataset}\label{sec:supervised-learning-and-training-dataset}

This section introduces the \textbf{formal setup} of \emph{Supervised Learning} in the context of neural networks. It defines \textbf{what data to use}, \textbf{what we want the network to learn}, and \textbf{how we measure learning success}. It's the \emph{conceptual skeleton} that the later mathematical tools (loss, gradient descent, backpropagation) will stand on.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{What is Supervised Learning?}}
\end{flushleft}
\definition{Supervised Learning} is a \textbf{machine learning paradigm} where the algorithm learns \textbf{from examples that include both the input and the correct output}. In other words, it learns \textbf{under supervision} from labeled data.

\highspace
The basic idea is simple. We give the model a set of \textbf{training examples}:
\begin{equation*}
    \mathcal{D} = \left\{
        \left( x_{1}, t_{1} \right),
        \left( x_{2}, t_{2} \right),
        \ldots,
        \left( x_{N}, t_{N} \right)
    \right\}
\end{equation*}
Formally, a \textbf{dataset} is:
\begin{equation}
    \mathcal{D} = \Biggl\{\left(x_{i}, t_{i}\right)\Biggr\}_{i=1}^{N}
\end{equation}
Where:
\begin{itemize}
    \item $x_{i}$ is the \textbf{input data} (e.g., an image, temperature readings, pixels, sensor values, etc.).
    \item $t_{i}$ is the \textbf{target output} (the \emph{label} or \emph{ground truth} we want the model to predict).
    \item $N$ is the total number of training examples.
\end{itemize}
The model (in our case, a neural network) tries to learn a \textbf{function} $f(\cdot)$ such that:
\begin{equation*}
    f\left(x_{i}\right) \approx t_{i} \quad \text{for all } i = 1, 2, \ldots, N
\end{equation*}
For all examples in the training set. In other words, to find a function $f(x)$ that not only fits the training data but also \textbf{generalizes} well to unseen data (i.e., it can correctly predict outputs for new inputs not in the training set). Formally, a \textbf{model} is a function:
\begin{equation}\label{eq:model-function}
    g(x; w) \text{ with parameters } w
\end{equation}
Where:
\begin{itemize}
    \item $g(\cdot; w)$ is the model (neural network) with parameters $w$ (weights and biases).
    \item The goal is to find the optimal parameters $w^{*}$ such that:
    \begin{equation}
        w^{*} = \arg\min_{w} E\left(w\right)
    \end{equation}
    Where $E(w)$ is a \textbf{loss function} that measures how far predictions $g(x_{i}; w)$ are from the true targets $t_{i}$ across the training set.
\end{itemize}
The method is called \textbf{supervised} because the learning process is \textbf{guided}: each input $x$ comes with the \textbf{correct answer} $t$. The network uses it to know whether it was right or wrong, and to adjust its weights accordingly.

\highspace
Independently by the paradigm used (supervised, unsupervised, reinforcement learning), with \definition{Training} we mean the \textbf{process of adjusting weights $w$ so that the network reproduces the mapping between inputs and outputs seen in the data}. This is done by \textbf{minimizing a loss function} that quantifies the difference between the network's predictions and the true targets in the training dataset.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Neural Networks as a Parametric Model}}
\end{flushleft}
In general, a neural network can be written as a \textbf{parametric function}:
\begin{equation}
    y\left(x; w\right) = g\left(x, w\right)
\end{equation}
Where:
\begin{itemize}
    \item $x$ is the input features (data).
    \item $w$ is the set of parameters (weights and biases in all layers) of the network.
    \item $y\left(x; w\right)$ is the output of the network (the prediction for input $x$ given parameters $w$).
    \item $;$ indicates that $y$ depends on both $x$ and $w$.
    \item $g(\cdot, \cdot)$ represents the entire computation performed by the neural network (all layers, activations, etc.). See above equation \ref{eq:model-function}.
\end{itemize}
We want $y\left(x_{n}; w\right)$ to be as close as possible to the target $t_{n}$ for each training example $\left(x_{n}, t_{n}\right)$ in the dataset $\mathcal{D}$. This is achieved by \textbf{optimizing the parameters $w$} to minimize a \textbf{loss function} that measures the discrepancy between predictions and targets across all training examples. Formally, find parameters $w^{*}$ that minimize a loss function $E(w)$:
\begin{equation}\label{eq:optimal-weights}
    w^{*} = \arg\min_{w} E\left(w\right)
\end{equation}
Where $E(w)$ quantifies the error between $y\left(x_{n}; w\right)$ and $t_{n}$ for all training examples. The loss function measures how wrong the model is across all training examples:
\begin{equation}
    E\left(w\right) = \displaystyle\sum_{n=1}^{N} \ell\left(t_{n}, y\left(x_{n}; w\right)\right)
\end{equation}
Where $\ell(\cdot, \cdot)$ is a loss function that quantifies the error for a single example (e.g., Mean Squared Error for regression, Cross-Entropy Loss for classification).

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon[regular]{lightbulb} \textbf{The power of this setup}}
\end{flushleft}
This framework allows us to covers a wide range of tasks:
\begin{itemize}
    \item \textbf{Regression}: Predicting continuous values (e.g., house prices, temperature).
    \item \textbf{Classification}: Assigning inputs to discrete categories (e.g., spam vs. not spam, image recognition).
    \item \textbf{Function Approximation}: Learning complex mappings from inputs to outputs.
\end{itemize}
By defining the problem in terms of inputs, targets, and a loss function, we can apply various optimization algorithms (like gradient descent) to train the neural network effectively. So, we must care only about:
\begin{itemize}
    \item The \textbf{structure of the network} (layers, activation functions).
    \item The \textbf{choice of loss function} (depends on the task).
    \item The \textbf{optimization algorithm} to minimize the loss.
\end{itemize}
This abstraction makes neural networks a versatile tool for many machine learning problems.

\begin{examplebox}[: Analogy]
    Imagine a student (the network) learning to solve math exercises.
    \begin{itemize}
        \item \textbf{Inputs} $x_{n}$ are the exercises given to the student by the teacher.
        \item \textbf{Targets} $t_{n}$ are the correct answers provided by the solution book.
        \item \textbf{Network} $g(x, w)$ is the student's method of solving the exercises, which depends on their current knowledge (parameters $w$).
        \item \textbf{Loss function} $E(w)$ measures how many answers the student got wrong compared to the solution book.
        \item \textbf{Optimization} (training) is the process of the student studying and adjusting their methods (updating $w$) to minimize mistakes on future exercises.
    \end{itemize}
    Over time, with enough practice (training examples), the student improves their ability to solve new exercises correctly (generalization). So training means making fewer mistakes over time by adjusting reasoning (weights).
\end{examplebox}