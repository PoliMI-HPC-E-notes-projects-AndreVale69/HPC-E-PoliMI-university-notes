\section{Introduction to Deep Learning}

\subsection{Machine Learning Foundations}

Humans and animals learn from experience. Computers, too, can improve performance when exposed to more data or feedback. But how do we formally define ``learning'' in a way that's precise enough for a engineering course? Tom Mitchell\footnote{%
    Tom Mitchell is a \emph{pioneer of machine learning}, both as a scientist and as an educator. His 1997 textbook, and especially that concise definition, shaped how an entire generation of students and researches understand Machine Learning (ML).
}, in 1997, proposed a now-classic definition:
\begin{definitionbox}[: Task, Experience, Performance]\index{Task, Experience, Performance}
    A computer program is said to learn from experience \textbf{E} with respect to some class of tasks \textbf{T} and a performance measure \textbf{P}, if its performance at tasks in \textbf{T}, as measured by \textbf{P}, improves with experience \textbf{E}.
\end{definitionbox}
\begin{itemize}
    \item \definition{Task (T)}: \hl{what the program is supposed to do}. For example, classification (spam vs not spam), regression (predict house prices) or game playing (chess).
    \item \definition{Experience (E)}: \hl{the data the algorithm is exposed to}. For example, training set of labeled emails (spam vs ham), past games played by an agent, sensor data from a robot.
    \item \definition{Performance measure (P)}: \hl{the metric used to evaluate progress}. For example, classification accuracy (F1 score), mean square error for regression, total reward in reinforcement learning.
\end{itemize}
A system ``learns'' if, after seeing more data or interacting more with the environment, its \textbf{measured performance improves}.

\begin{examplebox}[: Definition in Action]
    Some scenarios:
    \begin{enumerate}
        \item \textbf{Email Spam Classifier}
        \begin{itemize}
            \item \textbf{T (task)}: Classify emails as spam.
            \item \textbf{E (experience)}: Training dataset of emails labeled as spam.
            \item \textbf{P (performance measure)}: Accuracy on unseen emails.
        \end{itemize}
        If accuracy improves as the classifier sees more labeled data, then computer program learning.
        \item \textbf{Self-Driving Car}
        \begin{itemize}
            \item \textbf{T}: Driving from A to B safely.
            \item \textbf{E}: Millions of hours of driving footage $+$ sensor readings.
            \item \textbf{P}: Fewer accidents per mile, shorter trip times.
        \end{itemize}
        If the car improves after more data, it has learned.
        \item \textbf{Chess Playing Agent}
        \begin{itemize}
            \item \textbf{T}: Win games.
            \item \textbf{E}: Past games played against itself or others.
            \item \textbf{P}: Win rate.
        \end{itemize}
        More games, better play, computer program learning.
    \end{enumerate}
\end{examplebox}

\noindent
This definition matters because is \textbf{broad and general} (covers supervised, unsupervised, and reinforcement learning), it stresses \textbf{measurable improvement} (no improvement, no learning), and highlights the \textbf{central role of data} (E) and evaluation (P).

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Why Mitchell's definition doesn't mentions ``Machine Learning'' explicitly}}
\end{flushleft}
\begin{enumerate}
    \item \textbf{It's meant to be \underline{general}}. Mitchell wasn't defining \emph{what ML is as a field}, but rather \emph{what it means for a program to learn}. He avoided vague terms like ``machine learning'' or ``artificial intelligence'' and instead described the \emph{process}:
    \begin{itemize}
        \item A program improves at a \textbf{Task (T)};
        \item Thanks to \textbf{Experience (E)};
        \item As measured by \textbf{Performance (P)}.
    \end{itemize}

    \item \textbf{Machine Learning $=$ building such programs}. So instead of saying ``\emph{Machine Learning is when...}'', he framed it as: ``\emph{a computer program is said to learn if...}''. That's why his definition became the \textbf{canonical operational definition of Machine Learning}.
    
    \item \textbf{It links directly to practice}. The definition is testable: we can check if a system improves with experience. This is much stronger than a philosophical definition like ``\emph{machine learning is making computers intelligent}''.
\end{enumerate}

\begin{examplebox}[: Analogy]
    Think of physics. Newton didn't define ``physics''. He defined \emph{laws of motion} and \emph{gravity}. From those definitions, physics as a discipline could build itself consistently.

    Similarly, Mitchell didn't define ``Machine Learning'' as a whole discipline. He defined \textbf{what it means for a program to learn}. The field then said: ``Machine Learning is the study of programs that satisfy this definition''.
\end{examplebox}

\noindent
Mitchell's definition tells us ML is \textbf{not about hardcoding solutions}, but about \textbf{improving performance with data-driven experience}, measurable by a task-specific metric.

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Why we start with Tom Mitchell's definition}}
\end{flushleft}
\begin{enumerate}
    \item \textbf{Machine Learning is broad and fuzzy}. People use ``learning'', ``AI'', ``intelligence'' loosely. By giving a \textbf{formal, authoritative definition} at the beginning, the course sets a \emph{clear baseline}: what do we mean by \emph{learning}? How do we recognize it in a program?
    \item \textbf{It frames the whole course}. Everything we explain later, supervised learning, neural networks, deep learning, must fit inside this triplet (Task, Experience, Performance). For example:
    \begin{itemize}
        \item Neural Network training? It's about improving P on T given more E.
        \item Reinforcement learning? Same template, different E and P.
    \end{itemize}
    \item \textbf{It's rigorous but simple}. Unlike philosophical definitions of intelligente, Mitchell's version is \textbf{operational}: it tells us \emph{how to test if learning is happening}. It works as a \textbf{scientific foundation}, ``\emph{if we can't measure performance improvement, we can't claim the program learned}''.
    \item \textbf{It avoids confusion later}. If we started with supervised learning or deep learning right away, we'd lack the general umbrella. With this definition first, we can always check: ``\emph{what is our T? what is our E? what is our P?}''.
\end{enumerate}

\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{Mathematical View}}
\end{flushleft}
Formally, suppose we have:
\begin{itemize}
    \item Dataset $D = \left\{\left(x_{i}, t_{i}\right)\right\}_{i=1}^{N}$ (inputs $+$ targets).
    \item A model $f_\theta(x)$ with parameters $\theta$.
    \item A loss function $L(f_\theta(x), t)$ that measures errors (P).
\end{itemize}
Learning means finding $\theta^{*}$ that minimizes the expected loss:
\begin{equation*}
    \theta^{*} = \arg\min_{\theta} \; \mathbb{E}_{\left(x,t\right) \sim E}\left[L \left(f_{\theta}(x), t\right)\right]
\end{equation*}
This equation will be explained more thoroughly in the following sections.