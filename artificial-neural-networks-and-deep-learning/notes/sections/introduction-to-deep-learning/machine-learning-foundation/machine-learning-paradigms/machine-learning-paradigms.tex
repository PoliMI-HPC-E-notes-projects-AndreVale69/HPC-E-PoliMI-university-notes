\subsubsection{Machine Learning Paradigms}

When Tom Mitchell gave us the \textbf{triplet (T, E, P)}, he provided a general definition of learning. But in practice, machine learning problems usually fall into a few \textbf{big paradigms}; categories defined by \emph{what kind of data (experience) we provide} and \emph{what kind of task we want solved}. These paradigms are like \textbf{different ways of framing the learning problem}:
\begin{enumerate}
    \item \textbf{Supervised Learning}: we give the algorithm examples of input and desired output. The goal is learn to map new inputs to outputs.
    \item \textbf{Unsupervised Learning}: we only give input data, no labels. The goal is discover hidden structures or representations.
    \item \textbf{Reinforcement Learning}: we don't provide explicit labels. The system interacts with an environment, receives \textbf{rewards or penalties}, and learns a strategy (policy) to maximize reward over time.
\end{enumerate}
These paradigms are important because are the \textbf{building blocks of the field}. Almost any ML problem can be described belonging to (or combining) these three. They differ mainly in the \textbf{nature of the data (E)} and the \textbf{type of feedback (P)} available. Understanding them helps in choosing the right algorithms and models for a problem.

\begin{examplebox}[: Analogy]
    Imagine teaching three kinds of students:
    \begin{itemize}
        \item \textbf{Supervised Learning student}: we show them math problems \emph{with answers}, and they learn how to solve similar ones.
        \item \textbf{Unsupervised Learning student}: we give them a pile of problems \emph{without answers}, and they try to find patterns (like grouping similar problems together).
        \item \textbf{Reinforcement Learning student}: we give them a puzzle game. They don't know the rules, but they learn through \emph{trial and error} because we give them rewards when they succeed.
    \end{itemize}
\end{examplebox}