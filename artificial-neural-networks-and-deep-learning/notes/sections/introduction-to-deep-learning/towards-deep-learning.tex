\subsection{Towards Deep Learning}

This course, and this notes, focuses \textbf{mostly on Supervised Learning}, with some unsupervised learning concepts and techniques. \textcolor{Green3}{\textbf{\emph{Why?}}}
\begin{itemize}
    \item Supervised Learning is the most widely used paradigm in practice (e.g., image classification, speech recognition, etc.);
    \item Many deep learning application (image recognition, NLP, etc.) are supervised tasks;
    \item Unsupervised learning will be touched when needed (e.g., representation learning, generative models, etc.);
\end{itemize}
Deep Learning is not a new paradigm, it's a \textbf{new approach} with supervised/unsupervised learning.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{What about Deep Learning? Iris Flower Example}}
\end{flushleft}
The Iris flower dataset is a classic dataset in machine learning, often used for classification tasks. It consists of 150 samples of iris flowers, each with four features: sepal length, sepal width, petal length, and petal width. The goal is to classify the flowers into three species: Iris setosa, Iris versicolor, and Iris virginica.
\begin{itemize}
    \item \textbf{Traditional Machine Learning Approach:}
    \begin{itemize}
        \item Extract ``good features'' from the raw data (e.g., petal length and width);
        \item Train a classifier (e.g., decision tree) on these features;
    \end{itemize}
    \item \textbf{Deep Learning Approach:}
    \begin{itemize}
        \item Learn both \textbf{features} and \textbf{classifier} simultaneously from the raw data;
    \end{itemize}
\end{itemize}
For example:
\begin{enumerate}
    \item If \textbf{features are simple} (e.g., petal length and sepal width), then the classification task is \textbf{easy}, and a simple model (e.g., decision tree) can achieve high accuracy;
    \item If \textbf{features are complex} (e.g., raw pixel values of flower images), then the classification task is \textbf{hard}, and the traditional approach \textbf{struggles to extract meaningful features};
    \item If \textbf{impossible to know} which features matter, then handcrafted features are \textbf{not enough}, and we need a model that can \textbf{learn features} from the data itself (e.g., a deep neural network).
    \item Deep Learning learns features \textbf{directly from raw data}, making it suitable for complex tasks where feature engineering is challenging or infeasible (hierarchical representations).
\end{enumerate}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{balance-scale} \textbf{Feature Engineering vs. Learned Features}}
\end{flushleft}
\begin{itemize}
    \item \definition{Feature Engineering (Traditional ML)}:
    \begin{itemize}
        \item Feature Engineering is the process of \textbf{using domain knowledge to extract features from raw data} that make machine learning algorithms work. It needs human experts to design and select features that are relevant to the task.
        \item \textbf{Problem:} requires domain expertise, time-consuming, and may not capture all relevant information. It is often brittle and not transferable to new tasks or domains.
    \end{itemize}


    \item \definition{Learned Features (Deep Learning)}:
    \begin{itemize}
        \item Learned Features are features that are \textbf{automatically learned by the model} from the raw data during training.
        \item Layers learn progressively:
        \begin{itemize}
            \item Lower layers learn simple patterns (e.g., edges, corners);
            \item Middle layers learn more complex patterns (e.g., eyes, wheels);
            \item Higher layers learn high-level concepts (e.g., faces, cars).
        \end{itemize}
        \item \textbf{Advantage:} optimized for the task at hand, can capture complex patterns, and are transferable to new tasks or domains. It requires less manual effort and often generalizes better to unseen data.
    \end{itemize}
\end{itemize}
