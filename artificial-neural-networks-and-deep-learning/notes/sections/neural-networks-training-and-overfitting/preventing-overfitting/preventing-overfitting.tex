\subsection{Preventing Overfitting}\label{sec:nn-preventing-overfitting}

So far we've seen:
\begin{itemize}
    \item \textbf{Overfitting}: when the model fits both the signal \emph{and} the noise in the training data, leading to poor generalization on unseen data.
    \item \textbf{Underfitting}: when the model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and test sets.
    \item \textbf{Cross-Validation}: how to detect when a model generalizes poorly using techniques like Hold-Out Validation, Leave-One-Out Cross-Validation (LOOCV), K-Fold Cross-Validation, and Nested Cross-Validation.
\end{itemize}
But detecting overfitting is only half the battle. The next crucial step is to implement strategies to \textbf{prevent or limit overfitting during training} and enhance the model's ability to generalize well to new, unseen data. This section presents the \textbf{three main families of solutions} that modern deep learning uses to \emph{control complexity} and \emph{improve generalization}.

\highspace
\textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{The Core Problem:}} Neural networks have enormous representational power, by the \emph{Universal Approximation Theorem} (page \pageref{thm:universal-approximation-theorem}), they can approximate any continuous function. However, if they have \textbf{too many parameters}, and \textbf{too little data} (or data with noise), they will \textbf{memorize} rather than \textbf{learn}. Preventing overfitting is thus about \textbf{introducing constraints or checks} that force the model to extract \textbf{essential structure} from the data, not incidental details.

\highspace
\textcolor{Green3}{\faIcon{check-circle} \textbf{Overview of Prevention Techniques.}} In this section, we will explore three main strategies to prevent overfitting in neural networks:
\begin{enumerate}
    \item \textbf{Training control}: \important{Early Stopping technique} (\autopageref{sec:early-stopping}). This method stops training when validation error starts increasing.
    \item \textbf{Model complexity control}: \important{Regularization (Weight Decay, L2) technique} (\autopageref{sec:weight-decay-l2-regularization}). This method adds a penalty when weights grow too large, because large weights often indicate memorization.
    \item \textbf{Randomization / Model averaging}: \important{Dropout technique} (\autopageref{sec:nn-dropout-stochastic-regularization}). This method randomly deactivates neurons during training, forcing the network to learn redundant representations that generalize better.
\end{enumerate}
Each of these reduce the \textbf{effective capacity} of the network in a different way. Either by limiting how long it trains, how larger weights can grow, or how tightly neurons depend on each other.

\newpage

\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{How these techniques relate to the Training Curve}}
\end{flushleft}
Similar to the curve of \textbf{Model Complexity vs. Error} shown in Figure \ref{fig:error-vs-model-complexity}, these techniques aim to find the optimal point where the model is complex enough to capture the underlying patterns in the data, but not so complex that it overfits. The \definition{Training vs. Validation Error Curve} plot (shown in Figure \ref{fig:training-validation-error-curve}) illustrates how training and validation errors evolve during training. The goal of these techniques is to keep the model in the region where both training and validation errors are low, avoiding the point where validation error starts to increase due to overfitting.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=\textwidth]{img/neural-networks-and-overfitting/training-vs-validation-loss.pdf}
    \caption{This plot illustrates the \definition{Training vs. Validation Error Curve} during the training of a neural network. Initially, both training and validation errors decrease as the model learns from the data. However, after a certain point (epoch 57), the validation error starts to increase while the training error continues to decrease, indicating that the model is beginning to overfit the training data. The optimal stopping point is where the validation error is minimized, which can be achieved using techniques like Early Stopping.}
    \label{fig:training-validation-error-curve}
\end{figure}

\noindent
Furthermore, all \textbf{these techniques operationalize the Ockham's Razor principle} we saw earlier: \hl{``prefer the simplest model that explains the data well''} (page \hqpageref{sec:ockhams-razor}). By constraining the model's capacity in various ways, we encourage it to focus on the most salient features of the data, leading to better generalization and performance on unseen data.