\section{Esami}

\subsection{14/06/2025}

\subsubsection*{Esercizio 1}

Si consideri la matrice $A \in \mathbb{R}^{n \times n}$ ed il vettore $\mathbf{x}^{*} \in \mathbb{R}$ tali che:
\begin{equation*}
    A = \begin{bmatrix}
        3 & -2 & 0 & 0 & \cdots & 0 \\
        -1 & 3 & -2 & 0 & \cdots & 0 \\
        0 & -1 & \ddots & \ddots & \ddots & \vdots \\
        0 & 0 & \ddots & \ddots & \ddots & 0 \\
        \vdots & \vdots & \vdots & -1 & 3 & -2 \\
        0 & 0 & \cdots & 0 & -1 & 3
    \end{bmatrix}
    \qquad
    \mathbf{x}^{*} = \begin{bmatrix}
        1 \\ 2 \\ 3 \\ \vdots \\ n - 1 \\ n
    \end{bmatrix}
\end{equation*}
\begin{enumerate}
    \item Utilizzando gli opportuni comandi MATLAB, si costruiscano la matrice $A$ ed il vettore $\mathbf{x}^{*}$ per $n = 10$. Si calcoli $\mathbf{b} \in \mathbb{R}^{10}$ tale che $\mathbf{b} = A \mathbf{x}^{*}$.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Il primo passaggio è quello di costruire la matrice $A$ e il vettore $\mathbf{x}^{*}$ in MATLAB. La matrice $A$ è una matrice tridiagonale con elementi specifici, mentre il vettore $\mathbf{x}^{*}$ è un vettore colonna con valori da 1 a 10. I comandi MATLAB per costruire questi oggetti sono i seguenti:
    \begin{lstlisting}[language=MATLAB]
n = 10;
A = diag(3*ones(n,1)) + diag(-1*ones(n-1,1),-1) + diag(-2*ones(n-1,1),1);
x_star = (1:n)';
b = A * x_star;
disp('Matrix A:');
disp(A);
disp('Vector x_star:');
disp(x_star);
disp('Vector b:');
disp(b);\end{lstlisting}
    \begin{lstlisting}
Matrix A:
     3    -2     0     0     0     0     0     0     0     0
    -1     3    -2     0     0     0     0     0     0     0
     0    -1     3    -2     0     0     0     0     0     0
     0     0    -1     3    -2     0     0     0     0     0
     0     0     0    -1     3    -2     0     0     0     0
     0     0     0     0    -1     3    -2     0     0     0
     0     0     0     0     0    -1     3    -2     0     0
     0     0     0     0     0     0    -1     3    -2     0
     0     0     0     0     0     0     0    -1     3    -2
     0     0     0     0     0     0     0     0    -1     3

Vector x_star:
     1
     2
     3
     4
     5
     6
     7
     8
     9
    10

Vector b:
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    21\end{lstlisting}

    \item Utilizzando il comando \texttt{lu} di MATLAB, si calcoli la fattorizzazione LU della matrice $A$ precedentemente costruita. Utilizzando il comando \texttt{spy}, si determini se si è verificato il fenomeno del \emph{fill-in}. Si commenti il risultato e si riportino tutti i comandi utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per calcolare la fattorizzazione LU della matrice $A$ in MATLAB, si utilizza il comando \texttt{lu}. Successivamente, si utilizza il comando \texttt{spy} per visualizzare la struttura delle matrici $L$ e $U$ e verificare la presenza del fenomeno del \emph{fill-in}. I comandi MATLAB sono i seguenti:
    \begin{lstlisting}[language=MATLAB]
[L,U,P] = lu(A);

figure;
subplot(1, 3, 1);
spy(A);
title('Original Matrix A');

subplot(1, 3, 2);
spy(L + U - eye(n));
title('L + U - I (after LU factorization)');

subplot(1, 3, 3);
spy(L + U - eye(n) - A);
title('Fill-in (new non-zeros in L+U)');\end{lstlisting}
    Il fenomeno del \definition{fill-in} si verifica quando la fattorizzazione LU introduce nuovi elementi non nulli nelle matrici $L$ e $U$ che non erano presenti nella matrice originale $A$. Più formalmente, il \emph{fill-in} si verifica quando:
    \begin{equation*}
        \text{pattern}\left(L + U - I\right) \nsubseteq \text{pattern}\left(A\right)
    \end{equation*}
    Ovvero quando la fattorizzazione LU crea nuovi elementi non nulli in posizioni in cui $A$ aveva zeri. Quindi, la matrice corretta da analizzare per il \emph{fill-in} è $L + U - I$, dove $I$ è la matrice identità. Questo perché $L$ e $U$ contengono gli elementi della matrice originale $A$ più quelli introdotti dalla fattorizzazione. Sottraendo l'identità, si rimuovono gli elementi diagonali che sono sempre presenti in $L$ e $U$. Se la matrice risultante ha più elementi non nulli rispetto ad $A$, allora si è verificato il \emph{fill-in}.
    \begin{itemize}
        \item Con \texttt{spy(A)} si visualizza la struttura della matrice originale $A$.
        \item Con \texttt{spy(L + U - eye(n))} si visualizza la struttura della matrice risultante dalla somma di $L$ e $U$ meno l'identità. Ma attenzione, questa matrice include ancora gli elementi originali di $A$ e non mostra direttamente il \emph{fill-in}.
        \item Con \texttt{spy(L + U - eye(n) - A)} si visualizza la matrice che rappresenta il \emph{fill-in}, ossia i nuovi elementi non nulli introdotti dalla fattorizzazione LU che non erano presenti in $A$.
    \end{itemize}
    \begin{figure}[!htp]
        \centering
        \includegraphics[width=\textwidth]{img/14-06-2025/ex1_2.pdf}
    \end{figure}
    Dalla figura, si può osservare che nonostante la matrice \texttt{L + U - I} abbia una struttura identica a quella di $A$, la matrice che rappresenta il \emph{fill-in} mostra che sono stati introdotti nuovi elementi non nulli, indicando che il fenomeno del \emph{fill-in} si è verificato durante la fattorizzazione LU.


    \item Utilizzando le matrice $L$ e $U$ calcolate al punto precedente e le funzioni \texttt{fwsub.m} e \texttt{bksub.m} si risolva il sistema lineare $A\mathbf{x} = \mathbf{b}$. Si riporti il risultato ottenuto ed i comandi utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per risolvere il sistema lineare $A\mathbf{x} = \mathbf{b}$ utilizzando la fattorizzazione LU, si procede in due passi: prima si risolve il sistema $L\mathbf{y} = \mathbf{b}$ tramite sostituzione in avanti, e poi si risolve il sistema $U\mathbf{x} = \mathbf{y}$ tramite sostituzione all'indietro. I comandi MATLAB per eseguire questi passaggi sono i seguenti:
    \begin{lstlisting}[language=MATLAB]
% Risolvi Ly = b usando sostituzione in avanti
y = fwsub(L, b);
% Risolvi Ux = y usando sostituzione all'indietro
x = bksub(U, y);
disp('Soluzione x ottenuta risolvendo Ax = b:');
disp(x);\end{lstlisting}
    E il risultato ottenuto sarà:
    \begin{lstlisting}
Soluzione x ottenuta risolvendo Ax = b:
     1
     2
     3
     4
     5
     6
     7
     8
     9
    10\end{lstlisting}


    \item Si calcoli la fattorizzazione LU della matrice $B = AA^{T}$, dove $A^{T}$ è la matrice trasposta di $A$. Si determini se è stato eseguito \emph{pivoting} e si riportino i comandi utilizzati. Utilizzare le matrici calcolate al punto precedente ed il comando \texttt{\textbackslash} di MATLAB per risolvere il sistema lineare $B\mathbf{x} = \mathbf{b}$.
    
    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per calcolare la fattorizzazione LU della matrice $B = AA^{T}$ in MATLAB, si utilizza il comando \texttt{lu}. Per verificare se è stato eseguito il \emph{pivoting}, si può controllare la matrice di permutazione $P$ restituita dalla funzione \texttt{lu}. I comandi MATLAB sono i seguenti:
    \begin{lstlisting}[language=MATLAB]
B = A * A';
[L_B, U_B, P_B] = lu(B);
disp('L factor of B:');
disp(L_B);
disp('U factor of B:');
disp(U_B);
disp('Permutation matrix P_B:');
disp(P_B);

if isequal(P_B, eye(n))
    disp('Il pivoting non e'' stato eseguito nella fattorizzazione LU di B.');
else
    disp('Il pivoting e'' stato eseguito nella fattorizzazione LU di B.');
end

x_B = B \ b;
disp('Soluzione x ottenuta risolvendo Bx = b usando \:');
disp(x_B);\end{lstlisting}
    Se il \emph{pivoting} è stato eseguito, la matrice di permutazione $P_B$ non sarà la matrice identità poiché il \emph{pivoting} comporta la riorganizzazione delle righe della matrice per migliorare la stabilità numerica della fattorizzazione LU. Quindi, se $P_B$ è diversa dalla matrice identità, significa che il \emph{pivoting} è stato eseguito. Si ricorda che la matrice di permutazione $P_B$ indica come le righe della matrice originale $B$ sono state riorganizzate durante il processo di fattorizzazione LU; gli elementi non nulli in $P_B$ indicano le posizioni delle righe originali nella matrice permutata. Per esempio, se la prima riga di $P_B$ ha un elemento non nullo nella terza colonna, significa che la terza riga di $B$ è stata spostata alla prima posizione nella matrice permutata.
    
    \begin{lstlisting}[basicstyle=\ttfamily\scriptsize,columns=fullflexible,breaklines=false]
L factor of B:
  1.0000        0        0        0        0        0        0        0        0    0
 -0.6923   1.0000        0        0        0        0        0        0        0    0
       0   0.2574   1.0000        0        0        0        0        0        0    0
       0        0  -0.2841   1.0000        0        0        0        0        0    0
  0.1538  -0.9802  -0.8847  -0.9461   1.0000        0        0        0        0    0
       0        0        0        0   0.4111   1.0000        0        0        0    0
       0        0        0        0        0  -0.3102   1.0000        0        0    0
       0        0        0        0        0        0  -0.4083   1.0000        0    0
       0        0        0        0        0        0        0  -0.4521   1.0000    0
       0        0        0  -0.3869  -0.9399  -0.7603  -0.7360  -0.7700  -0.8297  1.0

U factor of B:
 13.0  -9.0000   2.0000        0        0        0        0        0        0        0
    0   7.7692  -7.6154   2.0000        0        0        0        0        0        0
    0        0  -7.0396  13.4851  -9.0000   2.0000        0        0        0        0
    0        0        0  -5.1688  11.4430  -8.4318   2.0000        0        0        0
    0        0        0        0   4.8645  -6.2082   1.8922        0        0        0
    0        0        0        0        0  -6.4476  13.2220  -9.0000   2.0000        0
    0        0        0        0        0        0  -4.8986  11.2082  -8.3796   2.0000
    0        0        0        0        0        0        0  -4.4239  10.5788  -8.1834
    0        0        0        0        0        0        0        0  -4.2174   6.3003
    0        0        0        0        0        0        0        0        0   0.3978

Permutation matrix P_B:
    1     0     0     0     0     0     0     0     0     0
    0     1     0     0     0     0     0     0     0     0
    0     0     0     1     0     0     0     0     0     0
    0     0     0     0     1     0     0     0     0     0
    0     0     1     0     0     0     0     0     0     0
    0     0     0     0     0     0     1     0     0     0
    0     0     0     0     0     0     0     1     0     0
    0     0     0     0     0     0     0     0     1     0
    0     0     0     0     0     0     0     0     0     1
    0     0     0     0     0     1     0     0     0     0

Il pivoting e' stato eseguito nella fattorizzazione LU di B.
Soluzione x ottenuta risolvendo Bx = b usando l'operatore backslash:
     1.9624
     4.8872
     8.7367
    13.4358
    18.8339
    24.6302
    30.2228
    34.4079
    34.7782
    26.5188
\end{lstlisting}
    

    \item (\textbf{T}) Definire il numero di condizionamento di una matrice $A$ e discutere la stabilità della soluzione numerica di un generico sistema lineare $A\mathbf{x} = \mathbf{b}$. Dimostrare come il residuo può essere usato come stimatore dell'errore.
    
    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} 
    
    \textbf{Numero di condizionamento.} Sia $A \in \mathbb{R}^{n \times n}$ una matrice \textbf{invertibile} e sia $\left\| \cdot \right\|$ una norma matriciale indotta (ad esempio, la norma 2 o la norma infinito). Il \definition{numero di condizionamento} di $A$ rispetto alla norma $\left\| \cdot \right\|$ è definito come:
    \begin{equation*}
        \kappa(A) = \left\| A \right\| \, \left\| A^{-1} \right\|
    \end{equation*}
    Dove $\left\| A \right\|$ è la norma della matrice $A$ e $\left\| A^{-1} \right\|$ è la norma della matrice inversa di $A$. Il numero di condizionamento $\kappa(A)$ misura \textbf{quanto} la soluzione di un sistema lineare ($x$ in $A\mathbf{x} = \mathbf{b}$) può amplificare perturbazioni di dati (su $\mathbf{b}$ o su $A$). Più tale numero è grande, più il problema è \definition{mal condizionato}, il che significa che piccole variazioni nei dati di input possono causare grandi variazioni nella soluzione.

    \highspace
    \textbf{Stabilità della soluzione numerica di $A\mathbf{x} = \mathbf{b}$}
    \begin{enumerate}
        \item \textbf{Condizionamento del problema} (\emph{sensibilità ai dati}). Per studiare il condizionamento del problema, si introducono delle perturbazioni sui dati del problema.

        Se perturbiamo solo il termine noto:
        \begin{equation*}
            A\left(\mathbf{x} + \delta \mathbf{x}\right) = \mathbf{b} + \delta \mathbf{b}
        \end{equation*}
        Allora, $A \delta \mathbf{x} = \delta \mathbf{b}$, e quindi $\delta \mathbf{x} = A^{-1} \delta \mathbf{b}$. Utilizzando le norme e $\mathbf{b} = A\mathbf{x}$, si ottiene:
        \begin{equation*}
            \dfrac{\left\| \delta \mathbf{x} \right\|}{\left\| \mathbf{x} \right\|} \le \dfrac{\left\|A^{-1}\right\| \, \left\| \delta \mathbf{b} \right\|}{\left\| \mathbf{x} \right\|} \le \dfrac{\left\|A^{-1}\right\| \, \left\| \delta \mathbf{b} \right\|}{\left\| A^{-1} \right\|^{-1} \left\| \mathbf{b} \right\|} = \kappa(A) \dfrac{\left\| \delta \mathbf{b} \right\|}{\left\| \mathbf{b} \right\|}
        \end{equation*}
        Questo significa che \textbf{un piccolo errore relativo su $\mathbf{b}$} può produrre un errore relativo su $\mathbf{x}$ amplificato da un fattore pari a $\kappa(A)$.


        \item \index{stabile all'indietro} \textbf{Stabilità dell'algoritmo} (\emph{errori di arrotondamento}). Un algoritmo è \definition{backward stable} (``stabile all'indietro'') se la soluzione numerica $\hat{\mathbf{x}}$ calcolata dall'algoritmo è esattamente la soluzione di un problema ``vicino'':
        \begin{equation*}
            \left(A + \delta A\right) \hat{\mathbf{x}} = \mathbf{b} + \delta \mathbf{b}
        \end{equation*}
        Con $\dfrac{\left\| \delta A \right\|}{\left\| A \right\|}$ e $\dfrac{\left\| \delta \mathbf{b} \right\|}{\left\| \mathbf{b} \right\|}$ piccoli (dell'ordine della precisione di macchina, $O\left(\varepsilon_{\text{mach}}\right)$). Dunque, combinando il condizionamento del problema (punto precedente) con la stabilità dell'algoritmo, si ottiene che l'errore relativo sulla soluzione numerica è limitato da:
        \begin{equation*}
            \dfrac{\left\| \hat{\mathbf{x}} - \mathbf{x} \right\|}{\left\| \mathbf{x} \right\|} \approx O\left(\kappa(A)\right) \, O\left(\varepsilon_{\text{mach}}\right)
        \end{equation*}
        Che significa che l'errore relativo sulla soluzione numerica è proporzionale al numero di condizionamento della matrice $A$ e alla precisione di macchina. Quindi:
        \begin{itemize}
            \item Se $\kappa(A) \varepsilon_{\text{mach}} \ll 1$, la soluzione numerica è generalmente accurata.
            \item Se $\kappa(A) \varepsilon_{\text{mach}} \approx 1$, la soluzione numerica può essere imprecisa, con poche cifre significative. Si dice che il problema è \definition{mal condizionato}.
            \item Se $\kappa(A) \varepsilon_{\text{mach}} > 1$, anche un algoritmo stabile può dare una soluzione con pochi (o zero) cifre significative. Si dice che il problema è \definition{gravemente mal condizionato} (o \definition{fortemente mal condizionato}). In altre parole, non è un problema dell'algoritmo, ma è il problema matematico ad essere intrinsecamente instabile da risolvere numericamente.
        \end{itemize}
    \end{enumerate}
    \textbf{Il residuo come stimatore dell'errore.} Sia $\hat{\mathbf{x}}$ la soluzione numerica approssimata del sistema lineare $A\mathbf{x} = \mathbf{b}$. Il \definition{residuo} associato a questa soluzione è definito come:
    \begin{equation*}
        \mathbf{r} = \mathbf{b} - A\hat{\mathbf{x}}
    \end{equation*}
    Sia $\mathbf{x}$ la soluzione esatta del sistema lineare e sia $e = \mathbf{x} - \hat{\mathbf{x}}$ l'errore commesso nella soluzione numerica. Allora, si ha:
    \begin{equation*}
        \mathbf{r} = \mathbf{b} - A\hat{\mathbf{x}} = A\mathbf{x} - A\hat{\mathbf{x}} = A\left(\mathbf{x} - \hat{\mathbf{x}}\right) = Ae
    \end{equation*}
    Quindi, l'errore $e$ può essere espresso in termini del residuo $\mathbf{r}$ come:
    \begin{equation*}
        Ae = \mathbf{r} \implies e = A^{-1}\mathbf{r}
    \end{equation*}
    Inoltre, utilizzando le norme, si ottiene:
    \begin{equation*}
        \left\| e \right\| = \left\| A^{-1}\mathbf{r} \right\| \le \left\| A^{-1} \right\| \, \left\| \mathbf{r} \right\|
    \end{equation*}
    Dividendo entrambi i membri per $\left\| \mathbf{x} \right\|$ e utilizzando la relazione $\left\| \mathbf{b} \right\| = \left\| A\mathbf{x} \right\| \leq \left\| A \right\| \, \left\| \mathbf{x} \right\|$, si ottiene:
    \begin{equation*}
        \dfrac{\left\| e \right\|}{\left\| \mathbf{x} \right\|} \le \left\| A^{-1} \right\| \, \dfrac{\left\| \mathbf{r} \right\|}{\left\| \mathbf{x} \right\|} \le \left\| A^{-1} \right\| \, \dfrac{\left\| \mathbf{r} \right\|}{\left\| A \right\|^{-1} \, \left\| \mathbf{b} \right\|} = \kappa(A) \, \dfrac{\left\| \mathbf{r} \right\|}{\left\| \mathbf{b} \right\|}
    \end{equation*}
    Quindi \textbf{il residuo relativo} $\dfrac{\left\| \mathbf{r} \right\|}{\left\| \mathbf{b} \right\|}$, moltiplicato per il numero di condizionamento $\kappa(A)$, fornisce una stima superiore (\textbf{upper bound}) dell'errore relativo nella soluzione numerica $\hat{\mathbf{x}}$. In altre parole, \hl{se il residuo è piccolo, allora l'errore nella soluzione numerica è anche piccolo}, a meno che la matrice $A$ non sia \hl{mal condizionata} (cioè, abbia un grande numero di condizionamento).

    \begin{takeawaysbox}
        Alcuni punti chiave da ricordare:
        \begin{itemize}
            \item \textbf{Residuo piccolo} non implica necessariamente un \textbf{errore piccolo} se la matrice è \textbf{mal condizionata} ($\kappa(A)$ grande).
            \item Se $A$ è \textbf{ben condizionata} (cioè, $\kappa(A)$ piccolo), allora un \textbf{residuo piccolo} garantisce un \textbf{errore piccolo}, quindi è un buon indicatore di accuratezza.
            \item In pratica si usa spesso anche il \textbf{residuo normalizzato}:
            \begin{equation*}
                \dfrac{\left\| \mathbf{r} \right\|}{\left\| A \right\| \, \left\| \hat{\mathbf{x}} \right\| + \left\| \mathbf{b} \right\|}
            \end{equation*}
            Che è un indicatore di backward error (errore all'indietro) più robusto. Dopodiché, moltiplicando questo residuo normalizzato per $\kappa(A)$, si ottiene l'errore forward (errore in avanti) stimato.
        \end{itemize}
    \end{takeawaysbox}

    \item Calcolare il condizionamento della matrice $B$ ed il residuo per fornire una stima dell'errore relativo commesso nella risoluzione del sistema lineare $B\mathbf{x} = \mathbf{b}$. Riportare i comandi utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per calcolare il condizionamento della matrice $B$ e il residuo associato alla soluzione numerica ottenuta, si utilizzano i seguenti comandi MATLAB:
    \begin{lstlisting}[language=MATLAB]
cond_B = cond(B);
r = b - B * x_B;
disp(['Condizionamento della matrice B: ', num2str(cond_B)]);
disp('Residuo r = b - Bx:');
disp(r);
norm_r = norm(r);
norm_B = norm(B);
norm_x_B = norm(x_B);
norm_b = norm(b);
residuo_normalizzato = norm_r / (norm_B * norm_x_B + norm_b);
disp([ ...
    'Residuo normalizzato: ', ...
    num2str(residuo_normalizzato) ...
]);
errore_stimato = cond_B * residuo_normalizzato;
disp([ ...
    'Stima dell''errore relativo: ', ...
    num2str(errore_stimato) ...
]);\end{lstlisting}
    E il risultato ottenuto sarà:
    \begin{lstlisting}
Condizionamento della matrice B: 911.3637
Residuo r = b - Bx:
   1.0e-13 *

         0
    0.0355
   -0.0711
   -0.0711
   -0.2842
   -0.4263
   -0.2842
    0.1421
         0
         0

Residuo normalizzato: 2.4185e-17
Stima dell'errore relativo: 2.2042e-14\end{lstlisting}
    Il sistema lineare $B\mathbf{x} = \mathbf{b}$ presenta un numero di condizionamento di circa $911.36$, indicando che il problema è moderatamente mal condizionato ($\kappa(B) \approx 9.11 \times 10^{2}$). Tuttavia, calcolando il residuo normalizzato, si ottiene un valore molto piccolo di circa $2.42 \times 10^{-17}$. Moltiplicando questo residuo per il condizionamento della matrice $B$, si ottiene una stima dell'errore relativo commesso nella risoluzione del sistema lineare, che risulta essere circa $2.20 \times 10^{-14}$. Questo indica che, nonostante il problema sia moderatamente mal condizionato, l'errore relativo nella soluzione numerica è ancora molto piccolo, suggerendo che la soluzione ottenuta è affidabile. Infatti, calcolando il prodotto $\kappa(B) \cdot \varepsilon_{\text{mach}}$ (dove $\varepsilon_{\text{mach}} \approx 2.22 \times 10^{-16}$ per la precisione doppia), si ottiene un valore di circa $2.02 \times 10^{-13}$, che è ancora molto piccolo, confermando che la soluzione numerica è accurata nonostante il condizionamento della matrice.
\end{enumerate}

\newpage

\subsubsection*{Esercizio 2}

Si consideri la funzione non lineare:
\begin{equation*}
    f(x) = \left(x - 2\right) e^{\left(x-1\right)}
\end{equation*}
Dotata dello zero $\alpha = 2$.
\begin{remarkbox}
    Quando l'esercizio specifica:
    \begin{equation*}
        f(x) = (x-2)e^{(x-1)} \quad \text{dotata dello zero } \alpha = 2
    \end{equation*}
    Intende semplicemente che:
    \begin{equation*}
        f\left(\alpha\right) = 0 \quad \text{con } \alpha = 2 \quad \Rightarrow \quad f(2) = (2-2)e^{(2-1)} = 0 \cdot e^{1} = 0
    \end{equation*}
    Con ``zero'' si intende la radice della funzione, ossia il valore di $x$ per cui $f(x) = 0$.
\end{remarkbox}
\begin{enumerate}
    \item (\textbf{T}) Si scriva il metodo di Newton per la determinazione numerica delle radici di una funzione $f \, : \, \left[a,b\right] \to \mathbb{R}$ come metodo di iterazioni di punto di fisso e si scrivano con precisione le condizioni per la convergenza, specificandone l'ordine. Si definisca un criterio d'arresto affidabile dandone motivazione.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Il \definition{Metodo di Newton come iterazione di punto fisso} viene formulato nel seguente modo. Dato il problema di trovare una radice $\alpha$ di una funzione $f : [a, b] \to \mathbb{R}$, con $\alpha \in \left[a,b\right]$ tale che $f(\alpha) = 0$, con $f$ derivabile in $\left[a,b\right]$, il \textbf{metodo di Newton} è:
    \begin{equation*}
        x_{k+1} = x_k - \dfrac{f(x_k)}{f'(x_k)}, \quad k = 0, 1, 2, \dots
    \end{equation*}
    Ovvero, la soluzione al passo $k+1$ viene calcolata a partire dalla soluzione al passo $k$ sottraendo il rapporto tra il valore della funzione e il valore della sua derivata prima in $x_k$. Questo metodo può essere interpretato come un \textbf{metodo di iterazioni di punto fisso} definendo la \emph{funzione di iterazione} $\varphi(x)$ come:
    \begin{equation*}
        \varphi(x) = x - \dfrac{f(x)}{f'(x)} \quad \Rightarrow \quad x_{k+1} = \varphi(x_k)
    \end{equation*}
    Infatti, $\alpha$ è una radice di $f$ se e solo se è un punto fisso di $\varphi$, ossia:
    \begin{equation*}
        f\left(\alpha\right) = 0 \quad \iff \quad \varphi\left(\alpha\right) = \alpha
    \end{equation*}
    \textbf{Condizioni di convergenza e ordine.}
    \begin{enumerate}
        \item \textbf{Convergenza locale} (la più usata per Newton). Sia $\alpha$ una \textbf{radice semplice} di $f$, ossia:
        \begin{equation*}
            f\left(\alpha\right) = 0 \qquad f'\left(\alpha\right) \neq 0
        \end{equation*}
        E sia $f \in \mathcal{C}^{2}$ in un intorno di $\alpha$ (ossia, $f$ è due volte continuamente derivabile vicino a $\alpha$). Allora, \textbf{esiste} un intorno $I$ di $\alpha$ tale che, per ogni scelta di $x_{0} \in I$, la successione generata dal metodo di Newton è ben definita e converge a $\alpha$.

        In questo caso la convergenza è \textbf{quadratica (ordine 2)}:
        \begin{equation*}
            \left\|e_{k+1}\right\| \le C \, \left\|e_k\right\|^{2} \quad \text{con } e_k = x_k - \alpha
        \end{equation*}
        Dove $C > 0$ è una costante dipendente da $f$ e dall'intorno $I$. Più precisamente (asintoticamente):
        \begin{equation*}
            e_{k+1} = \dfrac{f''\left(\alpha\right)}{2f'\left(\alpha\right)} \, e_k^{2} + o\left(e_k^{3}\right)
        \end{equation*}
        Dove $o\left(e_k^{3}\right)$ indica termini di ordine superiore a $e_k^{2}$. Se invece $\alpha$ è una radice di molteplicità $m > 1$, Newton converge solo \textbf{linearmente} (ordine 1) con fattore di convergenza:
        \begin{equation*}
            \left\|e_{k+1}\right\| \le \dfrac{m-1}{m} \, \left\|e_k\right\|
        \end{equation*}

        \item \textbf{Condizioni ``globali'' (sufficienti) via punto fisso su un intervallo}. Per usare il teorema delle contrazioni di punto fisso, basta garantire che $\varphi$ sia una contrazione su un intervallo chiuso $[a,b]$ contenente la radice $\alpha$. Quindi, si calcola la derivata di $\varphi$:
        \begin{equation*}
            \varphi'(x) = 1 - \dfrac{\left(f'(x)\right)^{2} - f(x) f''(x)}{\left(f'(x)\right)^{2}} = \dfrac{f(x) f''(x)}{\left(f'(x)\right)^{2}}
        \end{equation*}
        Le condizioni sufficienti per la convergenza globale sono:
        \begin{enumerate}
            \item $f \in \mathcal{C}^{2} \left(I\right)$ e $f'(x) \neq 0$ per ogni $x \in I = [a,b]$ (Newton è ben definito, ossia non si divide per zero).
            \item $\varphi(I) \subseteq I$ (ossia, l'immagine di $I$ tramite $\varphi$ è contenuta in $I$, garantendo che le iterazioni rimangono in $I$).
            \item Esiste una costante $q < 1$ tale che:
            \begin{equation*}
                \sup_{x \in I} \left| \varphi'(x) \right| =
                \sup_{x \in I} \left|\dfrac{f(x)f''(x)}{\left(f'(x)\right)^{2}}\right| \le q < 1
            \end{equation*}
            Allora $\varphi$ è una contrazione, ed esiste un unico punto fisso $\alpha \in I$ e $k_t \to \alpha$ per ogni $x_0 \in I$. In altre parole, la convergenza è garantita per ogni scelta di $x_0 \in I$. In questo schema, la garanzia è di \textbf{convergenza lineare} con fattore di convergenza $\le q$ (ossia, l'errore si riduce di almeno un fattore $q$ ad ogni iterazione).
        \end{enumerate}
    \end{enumerate}
    \textbf{Criterio d'arresto affidabile.} Un criterio di arresto robusto dovrebbe controllare:
    \begin{enumerate}
        \item Quanto bene $x_k$ (l'ultima iterata) soddisfa l'equazione (\textbf{residuo}, ossia $|f(x_k)|$). In questo modo si verifica se si è effettivamente vicini a una radice (ossia, se il valore della funzione è vicino a zero).
        \item Se l'iterazione sta ancora cambiando in modo significativo (\textbf{incremento}, ossia $|x_k - x_{k-1}|$). Questo aiuta a evitare di fermarsi prematuramente quando si è vicini alla radice ma non si è ancora abbastanza vicini.
    \end{enumerate}
    In parole semplici, il metodo deve fermarsi quando sia il valore della funzione che la differenza tra iterazioni successive sono entrambi piccoli. Un possibile criterio di arresto potrebbe essere:
    \begin{equation*}
        \left|f\left( x_{k} \right)\right| \le \tau_{f} \quad \text{e} \quad \left|x_{k+1} - x_{k}\right| \le \tau_{x} \, \left(1 + \left| x_{k+1} \right|\right)
    \end{equation*}
    Dove:
    \begin{itemize}
        \item \textbf{Criterio sul residuo}:
        \begin{equation*}
            \left|f\left( x_{k} \right)\right| \le \tau_{f}
        \end{equation*}
        Ovvero, il valore assoluto della funzione in $x_k$ deve essere inferiore a una tolleranza predefinita $\tau_{f}$.

        \item \textbf{Criterio sull'incremento} (relativo):
        \begin{equation*}
            \left|x_{k+1} - x_{k}\right| \le \tau_{x} \, \left(1 + \left| x_{k+1} \right|\right)
        \end{equation*}
        Ovvero, la differenza tra iterazioni successive deve essere inferiore a una tolleranza relativa $\tau_{x}$.
    \end{itemize}
    \textbf{Motivazione.} Questo criterio combina due aspetti importanti della convergenza:
    \begin{itemize}
        \item Il criterio sul residuo assicura che si stia effettivamente avvicinando a una radice della funzione. Utilizzando solo questo criterio, si potrebbe fermarsi in un punto dove la funzione è piccola ma non necessariamente vicino alla radice (plateau o minimi locali).
        \item Il criterio sull'incremento assicura che le iterazioni stiano effettivamente convergendo e non stiano oscillando o stagnando. Utilizzando solo questo criterio, si potrebbe fermarsi in un punto dove le iterazioni non stanno più cambiando significativamente, ma la funzione potrebbe ancora essere lontana da zero.
    \end{itemize}
    Utilizzando entrambi i criteri, si può essere più sicuri che il metodo di Newton abbia effettivamente trovato una buona approssimazione della radice desiderata.
 
    
    \item Si verifichi graficamente che $\alpha = 2$ è una radice per la funzione $f(x)$. Si riportino tutti i comandi MATLAB usati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per verificare graficamente che $\alpha = 2$ è una radice della funzione $f(x) = (x-2)e^{(x-1)}$, si può utilizzare MATLAB per tracciare il grafico della funzione e osservare dove essa interseca l'asse delle ascisse (ossia, dove $f(x) = 0$). Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
x = linspace(0, 4, 400); % Intervallo da 0 a 4 con 400 punti
f = (x - 2) .* exp(x - 1); % Definizione della funzione
figure;
plot(x, f, 'b-', 'LineWidth', 2); % Grafico della funzione
hold on;
yline(0, 'r--'); % Asse x
xlabel('x');
ylabel('f(x)');
title('Grafico della funzione f(x) = (x - 2)e^{(x-1)}');
grid on;
legend('f(x)', 'y = 0');
hold off;\end{lstlisting}
    E il grafico risultante mostra chiaramente che la funzione $f(x)$ interseca l'asse delle ascisse in corrispondenza di $x = 2$, confermando che $\alpha = 2$ è effettivamente una radice della funzione.
    \begin{figure}[!htp]
        \centering
        \includegraphics[width=\textwidth]{img/14-06-2025/ex2_2.pdf}
        \caption{Grafico della funzione $f(x) = (x-2)e^{(x-1)}$ che mostra l'intersezione con l'asse delle ascisse in $x = 2$.}
        \label{fig:ex2_2}
    \end{figure}
    
    
    \item \phantomsection\label{itm:es2.3} Si consideri il metodo delle iterazioni di punto fisso per l'approssimazione dello zero $\alpha$ di $f(x)$ usando la funzione di iterazione
    \begin{equation*}
        \phi = x - \dfrac{\left(x-2\right) e^{\left(x-2\right)}}{2e-1}
    \end{equation*}
    Si verifichi graficamente che lo zero $\alpha$ di $f(x)$ coincide con un punto fisso di $\phi(x)$ e si riportino i comandi MATLAB usati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per verificare graficamente che lo zero $\alpha = 2$ di $f(x)$ coincide con un punto fisso della funzione di iterazione $\phi(x) = x - \dfrac{(x-2)e^{(x-2)}}{2e-1}$, si può utilizzare MATLAB per tracciare il grafico di $\phi(x)$ insieme alla retta $y = x$. I punti in cui i due grafici si intersecano corrispondono ai punti fissi di $\phi(x)$. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
phi = @(x) x - ((x - 2) .* exp(x - 2)) / (2 * exp(1) - 1); % Definizione della funzione di iterazione
figure;
fplot(phi, [0, 4], 'b-', 'LineWidth', 2); % Grafico di phi(x)
hold on;
fplot(@(x) x, [0, 4], 'r--', 'LineWidth', 2); % Grafico della bisettrice y = x
xlabel('x');
ylabel('\phi(x) e y = x');
title('Grafico della funzione di iterazione \phi(x) e della bisettrice y = x');
grid on;
legend('\phi(x)', 'y = x');
hold off;\end{lstlisting}
    E il grafico risultante mostra chiaramente che la funzione di iterazione $\phi(x)$ interseca la retta $y = x$ in corrispondenza di $x = 2$, confermando che lo zero $\alpha = 2$ di $f(x)$ coincide con un punto fisso di $\phi(x)$.
    \begin{figure}[!htp]
        \centering
        \includegraphics[width=\textwidth]{img/14-06-2025/ex2_3.pdf}
        \caption{Grafico della funzione di iterazione $\phi(x)$ e della bisettrice $y = x$ che mostra l'intersezione in $x = 2$.}
        \label{fig:ex2_3}
    \end{figure}
    
    
    \item (\textbf{T}) \phantomsection\label{itm:es2.4} Sempre considerando il metodo delle iterazioni di punto fisso e la funzione di iterazione (equazione al punto \ref{itm:es2.3}), si determini l'ordine di convergenza del metodo ad $\alpha$ per un'iterata iniziale $x^{(0)}$ ``sufficientemente'' vicino ad $\alpha$. Si motivi la risposta data alla luce della teoria.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Data la funzione di iterazione:
    \begin{equation*}
        \phi(x) = x - \dfrac{(x-2)e^{(x-2)}}{2e-1}
    \end{equation*}
    Si definisce $g$ per comodità:
    \begin{equation*}
        g(x) = \left(x-2\right)e^{(x-2)}
    \end{equation*}
    Quindi, la funzione di iterazione può essere riscritta come:
    \begin{equation*}
        \phi(x) = x - \dfrac{g(x)}{2e-1}
    \end{equation*}
    Per determinare l'ordine di convergenza del metodo delle iterazioni di punto fisso, si calcola la derivata prima di $\phi(x)$:
    \begin{equation*}
        \phi'(x) = 1 - \dfrac{g'(x)}{2e-1}
    \end{equation*}
    Dove:
    \begin{equation*}
        g'(x) = e^{(x-2)} + (x-2)e^{(x-2)} = e^{(x-2)} \left(1 + (x-2)\right) = e^{(x-2)} (x-1)
    \end{equation*}
    Quindi:
    \begin{equation*}
        \phi'(x) = 1 - \dfrac{e^{(x-2)} (x-1)}{2e-1}
    \end{equation*}
    Ora, si calcola $\phi'(\alpha)$ con $\alpha = 2$:
    \begin{equation*}
        \phi'(2) = 1 - \dfrac{e^{(2-2)} (2-1)}{2e-1} = 1 - \dfrac{1 \cdot 1}{2e-1} = 1 - \dfrac{1}{2e-1} = \dfrac{2e-2}{2e-1}
    \end{equation*}
    Valore numerico:
    \begin{equation*}
        \phi'(2) \approx \dfrac{2 \cdot 2.71828 - 2}{2 \cdot 2.71828 - 1} = \dfrac{3.43656}{4.43656} \approx 0.774
    \end{equation*}
    Poiché $0 < \phi'(\alpha) < 1$ (con $\alpha = 2$), secondo la teoria delle iterazioni di punto fisso, il metodo converge \textbf{linearmente} ad $\alpha$ per un'iterata iniziale $x^{(0)}$ sufficientemente vicina ad $\alpha$. In particolare, l'ordine di convergenza è 1, e il fattore di convergenza è approssimativamente $0.774$. Questo significa che l'errore si riduce di circa il $77.4\%$ ad ogni iterazione, quando si è vicini alla radice.
    
    
    \item Considerando la funzione di iterazione $\phi(x)$ al punto \ref{itm:es2.3}, si utilizzi la funzione MATLAB \texttt{ptofis.m} con $x^{(0)} = 1.5$, tolleranza $tol = 10^{-4}$ e numero massimo di iterazioni $N_{max} = 1000$. Si riportino il numero di iterazioni $N$, i valori delle iterate $x^{(1)}$ e $x^{(2)}$, la differenza tra iterate successive $\left| x^{(N)} - x^{(N-1)} \right|$, insieme a tutti i comandi MATLAB utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per utilizzare la funzione MATLAB \texttt{ptofis.m} con la funzione di iterazione $\phi(x)$, si definisce prima la funzione di iterazione in MATLAB e poi si chiama la funzione \texttt{ptofis.m} con i parametri specificati. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
x0 = 1.5; % Iterata iniziale
tol = 1e-4; % Tolleranza
Nmax = 1000; % Numero massimo di iterazioni
[x, N] = ptofis(x0, Nmax, tol, phi);
disp(['Numero di iterazioni: ', num2str(N)]);
disp(['x^(1) = ', num2str(x(1))]);
disp(['x^(2) = ', num2str(x(2))]);
disp(['Differenza tra iterate successive: ', num2str(abs(x(N) - x(N-1)))]);\end{lstlisting}
    Il risultato ottenuto è:
    \begin{lstlisting}
Numero di iterazioni: 32
x^(1) = 1.5
x^(2) = 1.5684
Differenza tra iterate successive: 0.0001088\end{lstlisting}
    Quindi, il metodo delle iterazioni di punto fisso ha richiesto 32 iterazioni per convergere alla radice con la tolleranza specificata. Le prime due iterate sono $x^{(1)} = 1.5$ e $x^{(2)} \approx 1.5684$. La differenza tra le ultime due iterate è circa $0.0001088$.
    
    
    \item Si utilizzi opportunamente la funzione MATLAB \texttt{stimap.m} per stimare l'ordine di convergenza. Si discutano criticamente i risultati ottenuti con quelli relativi al punto \ref{itm:es2.4} e si riportino i comandi MATLAB utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per stimare l'ordine di convergenza utilizzando la funzione MATLAB \texttt{stimap.m}, si può passare la sequenza delle iterate ottenute dal metodo delle iterazioni di punto fisso. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
[p, c] = stimap(x);
disp('Stima dell''ordine di convergenza p:');
disp(p);
disp('Stima del fattore di abbattimento c:');
disp(c);\end{lstlisting}
    Il risultato ottenuto è:
    \begin{lstlisting}
Stima dell'ordine di convergenza p:
  Columns 1 through 10

         0         0    1.2090    1.1786    1.1524    1.1293    1.1090    1.0910    1.0752    1.0616

  Columns 11 through 20

    1.0500    1.0403    1.0322    1.0256    1.0202    1.0159    1.0125    1.0098    1.0076    1.0060

  Columns 21 through 30

    1.0046    1.0036    1.0028    1.0022    1.0017    1.0013    1.0010    1.0008    1.0006    1.0005

  Columns 31 through 32

    1.0004    1.0003

Stima del fattore di abbattimento c:
  Columns 1 through 10

         0         0    1.6194    1.4889    1.3816    1.2903    1.2113    1.1426    1.0829    1.0314

  Columns 11 through 20

    0.9873    0.9498    0.9183    0.8920    0.8701    0.8521    0.8373    0.8252    0.8154    0.8074

  Columns 21 through 30

    0.8010    0.7957    0.7915    0.7881    0.7854    0.7832    0.7815    0.7801    0.7790    0.7781

  Columns 31 through 32

    0.7774    0.7768\end{lstlisting}
    Dalla stima dell'ordine di convergenza $p$, si osserva che l'ordine tende a 1 man mano che le iterazioni procedono, confermando la conclusione del punto \ref{itm:es2.4} che il metodo converge linearmente. Il fattore di abbattimento $c$ si avvicina a un valore inferiore a 1, indicando che l'errore si riduce ad ogni iterazione. Questi risultati sono coerenti con la teoria delle iterazioni di punto fisso, che prevede una convergenza lineare quando la derivata della funzione di iterazione in corrispondenza del punto fisso è compresa tra 0 e 1.
\end{enumerate}

\newpage

\subsubsection*{Esercizio 3}

Data una funzione $f \in \mathcal{C}^{0} \left(\left[0, 1\right]\right)$, si consideri il problema di approssimazione numerica dell'integrale:
\begin{equation*}
    I(f) = \int_{0}^{1} f(x) \, dx
\end{equation*}
Mediante una formula di quadratura composita con $n$ sottointervalli equispaziati di $\left[0, 1\right]$.
\begin{enumerate}
    \item (\textbf{T}) Si introduca, in generale, il problema dell'approssimazione numerica dell'integrale sopra definito, tramite formule di quadrature sia semplici che composite, definendo con precisione tutta la notazione utilizzata. Si introducano i concetti di ordine di convergenza e grado di esattezza.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Sia $f \in \mathcal{C}^{0}\left(\left[0,1\right]\right)$ una funzione continua definita sull'intervallo $\left[0,1\right]$. Sia definito l'integrale:
    \begin{equation*}
        I(f) = \int_{0}^{1} f(x) \, dx
    \end{equation*}
    In generale, quando l'integrale non può essere calcolato esattamente o il calcolo esatto è troppo complesso, si ricorre a metodi di approssimazione numerica chiamati \definition{formule di quadratura} usando un \definition{operatore di quadratura} $Q$ che fornisce un'approssimazione numerica di $I(f)$.

    \highspace
    \textbf{Formule di quadratura semplici}. Una \textbf{formula di quadratura semplice} su $\left(\left[a,b\right]\right)$ ha la forma generale:
    \begin{equation*}
        Q(f) = \sum_{i=0}^{m} w_i \, f\left( x_i \right)
    \end{equation*}
    Dove:
    \begin{itemize}
        \item $x_i \in \left[a,b\right]$ sono i \textbf{nodi di quadratura} (i.e., i punti in cui la funzione viene valutata).
        \item $w_i \in \mathbb{R}$ sono i \textbf{pesi di quadratura} associati ai nodi (i.e., i coefficienti che pesano il contributo di ciascuna valutazione della funzione).
        \item $m + 1$ è il numero totale di nodi (e pesi) utilizzati nella formula (i.e., il numero di punti di valutazione meno uno).
    \end{itemize}
    L'\definition{errore di quadratura} è definito come:
    \begin{equation*}
        E(f) = I(f) - Q(f)
    \end{equation*}
    Ovvero la differenza tra il valore esatto dell'integrale e l'approssimazione fornita dalla formula di quadratura. Esempi classici sono la formula del punto medio, la formula del trapezio e la formula di Simpson.

    \highspace
    \textbf{Formule di quadratura composite}. Poiché le formule di quadratura semplici possono essere imprecise per funzioni complesse o su intervalli ampi, si utilizzano spesso \textbf{formule di quadratura composite}. Queste suddividono l'intervallo $\left[a,b\right]$ in $n$ sottointervalli più piccoli e applicano una formula di quadratura semplice su ciascun sottointervallo.

    Sia $n$ il numero di sottointervalli, e sia $h = \dfrac{b-a}{n}$ la larghezza di ciascun sottointervallo. I nodi di suddivisione sono dati da:
    \begin{equation*}
        x_i = a + i h \quad \text{per } i = 0, 1, \dots, n \quad \text{con } h = \dfrac{b-a}{n}
    \end{equation*}
    La formula di quadratura composita è quindi:
    \begin{equation*}
        Q_n(f) = \sum_{i=0}^{n} \omega_i f\left( x_i \right)
    \end{equation*}
    Dove $\omega_i$ sono i pesi associati ai nodi $x_i$ nei sottointervalli e $f\left( x_i \right)$ sono le valutazioni della funzione nei nodi.

    Adesso, si applica questa teoria al caso specifico dell'integrale su $\left[0,1\right]$. Dunque, si suddivide l'intervallo $\left[0,1\right]$ in $n$ sottointervalli equispaziati:
    \begin{equation*}
        x_i = 0 + ih = ih \quad \text{con } h = \dfrac{1-0}{n} = \dfrac{1}{n}, \quad i = 0, 1, \dots, n
    \end{equation*}
    Applicando una formula semplice su ciascun sottointervallo e sommando i contributi, si ottiene una \textbf{formula di quadratura composita}:
    \begin{equation*}
        Q_n(f) = \sum_{i=0}^{n} \omega_i f\left( x_i \right)
    \end{equation*}
    Dove $\omega_i$ sono i pesi associati ai nodi $x_i$. L'approssimazione dell'integrale è quindi:
    \begin{equation*}
        I_n(f) \approx Q_n(f) \qquad \text{con errore } E_n(f) = I(f) - Q_n(f)
    \end{equation*}

    \textbf{Ordine di convergenza.} Si dice che una formula di quadratura composita ha \definition{ordine di convergenza} $p$ se esiste una costante $C>0$, indipendente da $h$, tale che:
    \begin{equation*}
        \left|E_n(f)\right| \le C \, h^{p}
        \quad \text{per } h \to 0
    \end{equation*}
    Per ogni funzione $f$ sufficientemente regolare. L'ordine $p$ misura \textbf{la velocità con cui l'errore tende a zero} all'aumentare del numero di sottointervalli.

    \highspace
    \textbf{Grado di esattezza.} Una formula di quadratura (semplice o composita) si dice \textbf{esatta di grado $r$} se:
    \begin{equation*}
        Q(f) = I(f) \quad \text{per ogni polinomio } f \in \mathbb{P}_r
    \end{equation*}
    Dove $\mathbb{P}_r$ è lo spazio dei polinomi di grado minore o uguale a $r$. Il \definition{grado di esattezza} è quindi il massimo grado dei polinomi per cui la formula fornisce il valore esatto dell'integrale.

    \highspace
    In conclusione, il problema dell'approssimazione numerica dell'integrale consiste nel sostituire l'operatore integrale con un opportuno operatore di quadratura, semplice o composito. La qualità dell'approssimazione è descritta dall'ordine di convergenza, che misura il decadimento dell'errore al tendere del passo a zero, e dal grado di esattezza, che indica la classe di polinomi integrati esattamente dalla formula.
    
    \item Sia ora $f(x) = \left(1 - 2x\right)e^{-2x}$. Utilizzando la funzione \texttt{quadcomp.m}, si calcoli l'integrale approssimato $I_{1}(f)$ corrispondente alla formula di quadratura di tipo semplice (ossia ottenuta con $n = 1$). Riportare il risultato ottenuto e i comandi MATLAB usati.
    
    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per calcolare l'integrale approssimato $I_{1}(f)$ utilizzando la funzione MATLAB \texttt{quadcomp.m} con $n = 1$, si definisce prima la funzione $f(x) = (1 - 2x)e^{-2x}$ in MATLAB e poi si chiama la funzione \texttt{quadcomp.m}. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
f = @(x) (1 - 2*x).*exp(-2*x);
a = 0;
b = 1;
M1 = 1; % numero di sottointervalli per la formula semplice
I1 = quadcomp(a, b, M1, f);
fprintf('Integrale approssimato I1 con n=1: %.8f\n', I1);\end{lstlisting}
    Il risultato ottenuto è:
    \begin{lstlisting}
Integrale approssimato I1 con n=1: 0.12955351\end{lstlisting}
    Quindi, l'integrale approssimato $I_{1}(f)$ calcolato con la formula di quadratura semplice (con $n = 1$) è circa $0.12955351$.

    \item \phantomsection\label{itm:es3.3} Verificare il grado di esattezza della formula di quadratura implementata in \texttt{quadcomp.m} calcolando gli errori $E_{i} = \left|I\left(p_i\right) - I_1 (p_i)\right|$ dove $p_i(x) = x^{i}$ per $i = 0, \dots, 4$. Riportare i comandi utilizzati e commentare i risultati ottenuti.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per verificare il grado di esattezza della formula di quadratura implementata in \texttt{quadcomp.m}, si calcolano gli errori $E_{i} = \left|I\left(p_i\right) - I_1 (p_i)\right|$ per i polinomi $p_i(x) = x^{i}$ con $i = 0, \dots, 4$. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
degrees = 0:4;
errors = zeros(size(degrees));
for i = degrees
    % Definizione del polinomio p_i(x) = x^i
    p_i = @(x) x.^i;
    % Calcolo dell'integrale esatto
    I_exact = integral(p_i, a, b);
    % Calcolo dell'integrale approssimato con n=1
    I_approx = quadcomp(a, b, M1, p_i);
    % Calcolo dell'errore
    errors(i+1) = abs(I_exact - I_approx);
    fprintf('Grado %d: Errore E_%d = %.8e\n', i, i, errors(i+1));
end\end{lstlisting}
    Il risultato ottenuto è:
    \begin{lstlisting}
Grado 0: Errore E_0 = 1.11022302e-16
Grado 1: Errore E_1 = 1.11022302e-16
Grado 2: Errore E_2 = 0.00000000e+00
Grado 3: Errore E_3 = 0.00000000e+00
Grado 4: Errore E_4 = 5.55555556e-03\end{lstlisting}
    Commento sui risultati ottenuti:
    \begin{itemize}
        \item Per i polinomi di grado 0 e 1, l'errore è praticamente zero (dell'ordine della precisione numerica di MATLAB), indicando che la formula di quadratura è esatta per questi gradi.
        \item Per i polinomi di grado 2 e 3, l'errore è esattamente zero, confermando che la formula di quadratura è esatta anche per questi gradi.
        \item Per il polinomio di grado 4, l'errore è circa $5.55555556e-03$, indicando che la formula di quadratura non è esatta per questo grado.
    \end{itemize}
    Quindi, si conclude che la formula di quadratura implementata in \texttt{quadcomp.m} ha un grado di esattezza pari a 3, poiché è esatta per tutti i polinomi fino al grado 3, ma non per il grado 4.

    \item Utilizzando la funzione \texttt{quadcomp.m}, si calcoli l'integrale approssimato $I_{n}(f)$ e, sapendo che $I(f) = e^{-2}$, si calcoli l'errore commesso $E_n (f) = \left| I(f) - I_n (f) \right|$ per $n = 5, 10, 20, 40$. Riportare i risultati ottenuti nella forma esponenziale e i comandi MATLAB usati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per calcolare l'integrale approssimato $I_{n}(f)$ utilizzando la funzione MATLAB \texttt{quadcomp.m} per diversi valori di $n$ e calcolare l'errore commesso $E_n (f) = \left| I(f) - I_n (f) \right|$, si chiama la funzione \texttt{quadcomp.m} per i valori specificati di $n$. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
n_values = [5, 10, 20, 40];
I_exact = exp(-2);
errors_n = zeros(size(n_values));
for idx = 1:length(n_values)
    n = n_values(idx);
    I_approx_n = quadcomp(a, b, n, f);
    errors_n(idx) = abs(I_exact - I_approx_n);
    fprintf('n = %d: Errore E_n = %.8e\n', n, errors_n(idx));
end\end{lstlisting}
    Il risultato ottenuto è:
    \begin{lstlisting}
n = 5: Errore E_n = 1.09681698e-05
n = 10: Errore E_n = 6.89334720e-07
n = 20: Errore E_n = 4.31434853e-08
n = 40: Errore E_n = 2.69740755e-09\end{lstlisting}
    Quindi, gli errori commessi per i diversi valori di $n$ sono:
    \begin{itemize}
        \item Per $n = 5$: $E_5 \approx 1.09681698 \times 10^{-5}$
        \item Per $n = 10$: $E_{10} \approx 6.89334720 \times 10^{-7}$
        \item Per $n = 20$: $E_{20} \approx 4.31434853 \times 10^{-8}$
        \item Per $n = 40$: $E_{40} \approx 2.69740755 \times 10^{-9}$
    \end{itemize}
    
    \item Riportare su un grafico in scala logaritmica l'andamento dell'errore in funzione di $h = 1 / n$ confrontandolo con l'andamento $h^{s}$ per un opportuno $s > 0$. Si riportino tutti i comandi utilizzati. Dedurre l'ordine di convergenza della formula di quadratura e commentare il risultato alla luce di quanto ottenuto al punto \ref{itm:es3.3}.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Per riportare su un grafico in scala logaritmica l'andamento dell'errore in funzione di $h = 1/n$ e confrontarlo con l'andamento $h^{s}$, si utilizzano i dati ottenuti nel punto precedente. Ecco i comandi MATLAB utilizzati:
    \begin{lstlisting}[language=MATLAB]
h_values = 1 ./ n_values;
figure;
loglog(h_values, errors_n, 'bo-', 'DisplayName', 'Errore E_n');
hold on;
s = 4; % ipotizziamo un ordine di convergenza s=4
loglog(h_values, h_values.^s, 'k--', 'DisplayName', sprintf('h^{%d}', s));
grid on;
xlabel('h = 1/n');
ylabel('Errore');
legend('show');
title('Andamento dell''errore in funzione di h');
hold off;\end{lstlisting}
    Il grafico risultante mostra l'andamento dell'errore in funzione di $h$ in scala logaritmica, insieme alla curva di riferimento $h^{s}$ con $s = 4$. 

    \begin{figure}[!htp]
        \centering
        \includegraphics[width=\textwidth]{img/14-06-2025/ex3_5.pdf}
        \caption{Andamento dell'errore in funzione di $h$ in scala logaritmica, confrontato con $h^{4}$.}
        \label{fig:ex3_5}
    \end{figure}

    Dall'osservazione del grafico, si nota che l'errore decresce rapidamente all'aumentare di $n$ (diminuzione di $h$), e la pendenza della curva dell'errore è simile a quella della curva di riferimento $h^{4}$. Questo suggerisce che l'ordine di convergenza della formula di quadratura è approssimativamente 4.

    \textbf{Commento sul risultato alla luce di quanto ottenuto al punto \ref{itm:es3.3}.}
    Nel punto \ref{itm:es3.3}, si è determinato che la formula di quadratura ha un grado di esattezza pari a 3. Secondo la teoria delle formule di quadratura, una formula con grado di esattezza $r$ tende ad avere un ordine di convergenza almeno pari a $r + 1$. Pertanto, un grado di esattezza di 3 implica un ordine di convergenza atteso di almeno 4, che è coerente con l'osservazione grafica ottenuta in questo punto. Questo conferma la validità della formula di quadratura utilizzata e la sua efficacia nell'approssimare l'integrale.
\end{enumerate}