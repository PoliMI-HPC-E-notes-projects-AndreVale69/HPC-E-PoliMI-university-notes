\section{Esami}

\subsection{24/07/2025}

\subsubsection*{Esercizio 1}

Si consideri la matrice $A \in \mathbb{R}^{n \times n}$ ed il vettore $\mathbf{b} \in \mathbb{R}^{n}$ tali che:
\begin{equation*}
    A = \begin{bmatrix}
        2 & -1 & 0 & 0 & \cdots & 0 \\
        -1 & 2 & -1 & 0 & \cdots & 0 \\
        0 & -1 & \ddots & \ddots & \ddots & \vdots \\
        0 & 0 & \ddots & \ddots & \ddots & 0 \\
        \vdots & \vdots & \vdots & -1 & 2 & -1 \\
        0 & 0 & \cdots & 0 & -1 & 2 \\
    \end{bmatrix}
    \hspace{3em}
    \mathbf{b} = \begin{bmatrix}
        -1 \\
        -1 \\
        -1 \\
        \vdots \\
        -1 \\
        -1 \\
    \end{bmatrix}
\end{equation*}
\begin{enumerate}
    \item Utilizzando gli opportuni comandi Matlab, si costruiscano la matrice $A$ ed il vettore $\mathbf{b}$ per $n = 7$. Utilizzando il comando \textbackslash si risolva il sistema lineare $A\mathbf{x} = \mathbf{b}$. Riportare $\mathbf{x}$ e tutti i comandi Matlab usati.
    
    \textcolor{Green3}{\textbf{\emph{Soluzione}}}
    \begin{lstlisting}[language=MATLAB]
% dimensione di n
n = 7;
% creiamo un vettore di 1 e aggiungiamo 1
A = diag(ones(n,1)+1) +         % diag. principale
    diag(ones(n-1,1)-2, 1) +    % diag. sopra principale
    diag(ones(n-1,1)-2, -1);    % diag. sotto principale
% creiamo vettore b
b = -ones(n,1);
% calcola soluzione di x
x = A\b;\end{lstlisting}
Il vettore \texttt{x} produce il seguente risultato:
\begin{equation*}
    \mathbf{x} = \begin{bmatrix}
        -3.5 \\
        -6 \\
        -7.5 \\
        -8 \\
        -7.5 \\
        -6 \\
        -3.5
    \end{bmatrix}
\end{equation*}

    \item Elencare e discutere:
    \begin{enumerate}
        \item Le condizioni sufficienti per la convergenza del metodo di Gauss-Seidel.
        \item Le condizioni necessarie e sufficienti per la convergenza del metodo di Gauss-Seidel.
    \end{enumerate}
    Data $B_{GS}$ la matrice di iterazione di Gauss-Seidel, dimostrare che\break $\left\| B_{GS} \right\| < 1$ implica la convergenza.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Le condizioni sufficienti per la convergenza del metodo di Gauss-Seidel sono 3:
    \begin{itemize}
        \item La matrice $A$ deve essere a \textbf{dominanza diagonale stretta per righe}:
        \begin{equation*}
            \left|a_{ii}\right| > \displaystyle\sum_{j \ne i} \left|a_{ij}\right| \hspace{1em} \forall i
        \end{equation*}
        \item La matrice $A$ deve essere \textbf{simmetrica definita positiva (SPD)}:
        \begin{equation*}
            \mathbf{x}^{T} A \mathbf{x} > 0 \hspace{1em} \forall \mathbf{x} \ne 0
        \end{equation*}
        \item La matrice $A$ deve essere una \textbf{Matrice di classe M (M-Matrice) non singolare}. Ovvero una matrice con diagonale positiva e elementi extradiagonali (non sulla diagonale) non positivi.
    \end{itemize}
    L'unica condizione necessarie e sufficiente per la convergenza è quando il raggio spettrale della matrice di iterazione $B_{GS}$ è minore di uno:
    \begin{equation*}
        \text{convergenza} \iff \rho(B_{GS}) < 1
    \end{equation*}
    \begin{proof}[Dimostrazione ($\left\| B_{GS} \right\| < 1$ implica la convergenza)]
        Il metodo di Gauss-Seidel si scrive
        \begin{equation*}
            x^{(k+1)} = B_{GS}x^{(k)} + c
        \end{equation*}
        Definendo l'errore $e^{(k)} = x^{(k)} - x^{*}$, si ha
        \begin{equation*}
            e^{(k+1)} = B_{GS} e^{(k)} \quad \Rightarrow \quad e^{(k)} = B_{GS}^k e^{(0)}
        \end{equation*}
        Se $\|B_{GS}\| < 1$, allora:
        \begin{equation*}
            \|e^{(k)}\| \le \|B_{GS}\|^k \|e^{(0)}\| \to 0,
        \end{equation*}
        Per $k \to \infty$. Quindi $x^{(k)} \to x^\ast$: il metodo converge.
    \end{proof}


    \item Verificare se la matrice $A$ soddisfa le condizioni precedenti riportate. Motivare le risposte e riportare i comandi utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}}
    \begin{lstlisting}[language=MATLAB]
first_cond = false;
for row = 1:n
    first_cond = abs(A(row, row)) > (abs(sum(A(row, 1:n))) - abs(A(row, row)));
    if first_cond == 0
        disp("La matrice NON e' a dominanza diagonale stretta per righe")
        break
    end
end

if first_cond
    disp("La matrice e' a dominanza diagonale stretta per righe")
end

% dimostrare che e' simmetrica e definita positiva
second_cond = issymmetric(A) && all(eig(A) > 0);
if second_cond
    disp("La matrice e' simmetrica definita positiva")
else
    disp("La matrice NON e' simmetrica definita positiva")
end

% dimostrare che e' una M-Matrice non singolare
% 1. Extradiagonali non positivi
n = size(A, 1);
% creiamo la matrice con solo la diagonale principale
% diag(diag(A)) e sottraiamo alla matrice A la diagonale
% principale per ottenere la matrice con solo le
% extradiagonali
offdiag = A - diag(diag(A));
% verifichiamo che tutte le extradiagonali siano <= 0
first_m_cond = all(offdiag(:) <= 0);
if first_m_cond == false
    disp("La matrice NON e' una M-matrice: extradiagonali positive")
end
% 2. Diagonale principale positiva
second_m_cond = all(diag(A) > 0);
if second_m_cond == false
    disp("La matrice NON e' una M-matrice: diagonale principale non positiva")
end
% 3. A e' non singolare, cioe' rango(A) = n
% si ricorda che una matrice e' singolare se det(A) = 0
% e che rango(A) = n se e solo se det(A) != 0
% perche' il determinante e' il prodotto degli autovalori
% e una matrice e' singolare se ha almeno un autovalore nullo
third_m_cond = (rank(A) == n);
if third_m_cond == false
    disp("La matrice NON e' una M-matrice: matrice singolare")
end

if first_m_cond && second_m_cond && third_m_cond
    disp("La matrice e' una M-matrice non singolare")
end\end{lstlisting}
    Come risultato finale, si ottiene che la matrice \texttt{A} rispetta le 3 condizioni sufficienti per convergere usando il metodo di Gauss-Seidel.


    \item \label{item: punto d - 24-07-2025} Usando la funzione \texttt{gs.m} si risolva il sistema lineare $Ax = b$ con il metodo iterativo di Gauss-Seidel per $x^{(0)} = \left(0, 0, 0, 0, 0, 0, 0\right)^{T}$, tolleranza $tol = 10^{-7}$ e massimo numero di iterazioni $N_{\max} = 700$. Indicata con $x_{GS}$ la soluzione ottenuta approssimata ottenuta, si riportino: il numero di iterazioni effettuate, l'errore $\left\| x_{GS} - x \right\|$ e tutti i comandi Matlab utilizzati.

    \textcolor{Green3}{\textbf{\emph{Soluzione.}}}
    \begin{lstlisting}[language=MATLAB]
x0 = zeros(n, 1);
tol = 1e-7;
n_max = 700;
[x_gs, k] = gs(A, b, x0, tol, n_max);
disp("Soluzione con Gauss-Seidel:")
disp(x_gs)
disp("Numero di iterazioni:")
disp(k)
% errore x_gs - x
err_gs = norm(x_gs - x);
disp("Errore tra soluzione esatta e soluzione con Gauss-Seidel:")
disp(err_gs)\end{lstlisting}
    Output:
    \begin{lstlisting}
Soluzione con Gauss-Seidel:
   -3.5000
   -6.0000
   -7.5000
   -8.0000
   -7.5000
   -6.0000
   -3.5000

Numero di iterazioni:
   103

Errore tra soluzione esatta e soluzione con Gauss-Seidel:
   1.4486e-06\end{lstlisting}


    \item Si riportino il valore del parametro $\alpha$ che massimizza la velocità di convergenza del metodo di Richardson stazionario ed il corrispondente raggio spettrale della matrice di iterazione.
   
    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Da definizione, il parametro $\alpha_{\mathrm{opt}}$ che massimizza la velocità di convergenza del metodo di Richardson è:
    \begin{equation*}
        \alpha_{\mathrm{opt}} = \dfrac{2}{\lambda_{\min}(A) + \lambda_{\max}(A)}
    \end{equation*}
    Dove $\lambda$ rappresenta il vettore degli autovalori della matrice $A$. Invece, il raggio spettrale della matrice di iterazione corrispondente al parametro $\alpha_{\mathrm{opt}}$ é:
    \begin{equation*}
        \rho\left(I - \alpha_{\mathrm{opt}}A\right) = \dfrac{
            \lambda_{\max}(A) - \lambda_{\min}(A)
        }{
            \lambda_{\max}(A) + \lambda_{\min}(A)
        }
    \end{equation*}
    Implementato quanto detto su MATLAB, il codice è:
    \begin{lstlisting}[language=MATLAB]
eigen_values = eig(A);
lambda_min = min(eigen_values);
lambda_max = max(eigen_values);
alpha_opt = 2 / (lambda_min + lambda_max);
disp("Parametro alpha che massimizza la velocita' di convergenza: " + alpha_opt)

rho = (lambda_max - lambda_min) / (lambda_max + lambda_min);
disp("Raggio spettrale del metodo di Richardson: " + rho);\end{lstlisting}
    Output:
    \begin{lstlisting}
Alpha che massimizza la velocita' di convergenza: 0.5
Raggio spettrale del metodo di Richardson: 0.92388\end{lstlisting}


    \item Si ripeta il punto \ref{item: punto d - 24-07-2025} usando la funzione \texttt{richardson.m} per applicare il metodo iterativo di Richardson stazionario alla soluzione del sistema lineare con parametro $\alpha_{\mathrm{opt}}$ calcolato al punto precedente. Si riportino la soluzione approssimata ottenuta ed il numero di iterazioni effettuate. Sulla base dei risultati ottenuti quale dei due metodi converge più velocemente?
    
    \textcolor{Green3}{\textbf{\emph{Soluzione.}}} Al punto \ref{item: punto d - 24-07-2025}, il metodo di iterazione aveva le seguenti caratteristiche:
    \begin{itemize}
        \item $x^{(0)} = \left(0, 0, 0, 0, 0, 0, 0\right)^{T}$
        \item $tol = 10^{-7}$
        \item $N_{\max} = 700$
    \end{itemize}
    Quindi, il codice MATLAB:
    \begin{lstlisting}[language=MATLAB]
x0 = zeros(n, 1);
tol = 1e-7;
n_max = 700;
[x_rich, k_rich, err_rich] = richardson(A, b, x0, alpha_opt, tol, n_max);
disp("Soluzione con Richardson:")
disp(x_rich)
disp("Numero di iterazioni: " + k_rich)
% errore x_rich - x
err_rich_final = norm(x_rich - x);
disp("Errore tra soluzione esatta e soluzione con Richardson: " + err_rich_final)\end{lstlisting}
    Output:
    \begin{lstlisting}
Soluzione con Richardson:
   -3.5000
   -6.0000
   -7.5000
   -8.0000
   -7.5000
   -6.0000
   -3.5000

Numero di iterazioni: 203
Errore tra soluzione esatta e soluzione con Richardson: 1.7286e-06\end{lstlisting}
    Il metodo di Gauss-Seidel ha impiegato la metà del numero di iterazioni rispetto al metodo di Richardson (103 contro 203), dimostrando che il metodo di iterazione che converge più rapidamente è Gauss-Seidel.
\end{enumerate}

\newpage

\subsubsection*{Esercizio 2}

Sia $f(x) = \log(5x^{2} + 1)$ definita nell'intervallo $I = \left[-2, 2\right]$. Si vuole approssimare $f$ con un polinomio interpolante $\Pi_{n} f$ di grado $n$ su $n+1$ nodi $x_{i}$ definiti su $I$. Siano inoltre $\left\{\overline{x}_{j}, \, j = 1, \dots, 701 \right\}$ 701 punti equispaziati su $I$ (estremi inclusi), per il calcolo dell'errore di interpolazione.

\begin{remarkbox}
    Prima di continuare con l'esercizio, è importante ricordare e capire il testo.
    \begin{itemize}
        \item Cosa si intende con ``approssimare $f$ con un polinomio interpolante $\prod_{n} f$ di grado $n$ su $n+1$ nodi $x_{i}$ definiti su $I$''? Vuol dire che:
        \begin{itemize}
            \item Si scelgono $n+1$ \textbf{nodi} (cioè punti distinti nell'intervallo $I = [-2, 2]$), chiamiamoli $x_0, x_1, \dots, x_n$.
            \item Si calcolano i valori della funzione in quei nodi: $f(x_0), f(x_1),\break \dots, f(x_n)$.
            \item Esiste ed è unico un \textbf{polinomio di grado al più} $n$ che ``passa'' per tutti questi punti, ovvero:
            \begin{equation*}
                \Pi_{n} f(x_i) = f(x_i), \quad i = 0, 1, \dots, n
            \end{equation*}
            Questo polinomio si chiama \definition{Polinomio Interpolante} di $f$ nei nodi dati.
        \end{itemize}
        Quindi, in altre parole, $\Pi_{n} f$ non è altro che una funzione polinomiale che coincide con $f$ in un insieme finito di punti, ed è usata per approssimare $f$ anche altrove nell'intervallo.

        \highspace
        Nota: si dice ``polinomio interpolante'' perché il polinomio \emph{interpola} la funzione, ovvero prende esattamente gli stessi valori della funzione $f$ in un insieme finito di punti (i nodi di interpolazione) e ``si inserisce'' fra questi valori, passando per essi. Inoltre, interpolare non significa approssimare. Interpolare vuol dire costruire una funzione (nel nostro caso un polinomio) che coincide \textbf{esattamente} con $f$ in punti scelti (i nodi), e la approssima negli altri.

        
        \item Perché vengono dati 701 punti equispaziati? Questi punti $\left\{\bar{x}_{j}\right\}$ non sono nodi di interpolazione. Servono, invece, come \textbf{griglia di controllo}:
        \begin{itemize}
            \item In ciascun punto $\bar{x}_{j}$ si calcola il valore esatto $f\left(\bar{x}_{j}\right)$.
            \item Poi si calcola il valore approssimato usando il polinomio interpolante $\Pi_{n} f\left(\bar{x}_{j}\right)$.
            \item La differenza:
            \begin{equation*}
                E\left(\bar{x}_{j}\right) = f\left(\bar{x}_{j}\right) - \Pi_{n} f\left(\bar{x}_{j}\right)
            \end{equation*}
            è l'\definition{Errore di Interpolazione} in quel punto.
        \end{itemize}
        Avendo tanti punti equispaziati (701 è un numero grande, quindi la griglia è fitta), si può stimare bene \textbf{quanto e come il polinomio interpolante si discosta da} $f$ su tutto l'intervallo $\left[-2, 2\right]$. Chiaramente, più punti vengono usati per testare, più accurata sarà la stima della \textbf{norma del massimo dell'errore}:
        \begin{equation*}
            \left\| f - \Pi_{n} f \right\|_{\infty} \approx \max_{1\le j \le 701} \left| f\left(\bar{x}_j\right) - \Pi_{n} f\left(\bar{x}_j\right) \right|
        \end{equation*}


        \item Cos'è l'errore di interpolazione? Teoricamente, per una funzione $f \in C^{n+1}$, vale la formula:
        \begin{equation*}
            f(x) - \Pi_{n} f(x) = \dfrac{f^{(n+1)}(\xi(x))}{(n+1)!} \displaystyle\prod_{i=0}^{n}(x - x_i)
        \end{equation*}
        Dove $\xi(x)$ è un punto (non noto) nell'intervallo. Questo indica che l'errore dipende:
        \begin{enumerate}
            \item Dalla derivata $(n+1)$-esima di $f$ (quanto $f$ è ``curva'');
            \item E dal termine $\displaystyle\prod (x - x_{i})$ che cresce con $n$ e con la scelta dei nodi.
        \end{enumerate}
        Nella pratica, non potendo conoscere $\xi(x)$, si calcola l'errore numericamente sui 701 punti equispaziati.
    \end{itemize}
    Quindi, per riassumere: interpolazione significa costruire un polinomio che ``passa'' per i valori noti di $f$ in $n+1$ nodi. L'errore di interpolazione è la differenza $f(x) - \Pi_{n} f(x)$, stimata sui 701 punti equispaziati. Quei punti servono solo come ``griglia di test'' per misurare quanto il polinomio approssima bene la funzione sull'intero intervallo.
\end{remarkbox}

\begin{enumerate}
    \item Fissando $n = 10$, costruire il polinomio interpolante $\Pi_{10} f$ su nodi equispaziati (estremi inclusi) e calcolare il massimo dell'errore di approssimazione sui punti $\left\{\bar{x}_{j}\right\}_{j = 1, \dots, 701}$. Riportare il risultato ottenuto e i comandi MATLAB usati.
    
    \textcolor{Green3}{\textbf{\emph{Soluzione}}}
    \begin{lstlisting}[language=MATLAB]
% funzione
f = @(x) log(5*x.^2 + 1); % funzione da approssimare

% griglia di controllo x_j
xj = linspace(-2, 2, 701);

% grado del polinomio
n = 10;

% nodi
xn = linspace(-2, 2, n + 1);

% polinomio interpolante di grado n sui nodi xn
Pf = polyfit(xn, f(xn), n);
% massimo errore di approssimazione
err = max(abs(f(xj) - polyval(Pf, xj)));
disp('Massimo errore di approssimazione');
disp(err);\end{lstlisting}
    Output:
    \begin{lstlisting}
Massimo errore di approssimazione
    0.9989\end{lstlisting}
    Escludendo la parte di setup, la quale non ha bisogno di spiegazioni approfondite, nella parte di calcolo effettivo, si lasciano alcune osservazioni:
    \begin{itemize}
        \item Comando \texttt{polyfit}:
        \begin{lstlisting}[language=MATLAB]
Pf = polyfit(xn, f(xn), n);\end{lstlisting}
        In una sola invocazione, esegue due compiti:
        \begin{enumerate}
            \item Prende i \textbf{nodi} \texttt{xn} e i valori della funzione \texttt{f(xn)};
            \item Calcola i coefficienti del \textbf{polinomio interpolante} di grado $n$ che passa esattamente per quei punti.
        \end{enumerate}
        Ovviamente, si potrebbe costruire a mano con la formula di Lagrange o Newton, ma MATLAB fornisce già un API. Il risultato di questa chiamata, è un vettore riga \texttt{Pf} con i coefficienti del polinomio in forma classica:
        \begin{equation*}
            p(x) = Pf(1) \, x^n + Pf(2) \, x^{n-1} + \dots + Pf(n) \, x + Pf(n+1)
        \end{equation*}


        \item Comando \texttt{polyval}:
        \begin{lstlisting}[language=MATLAB]
polyval(Pf, xj)\end{lstlisting}
        Valuta il polinomio definito da \texttt{Pf} nei punti \texttt{xj}. Quindi sta calcolando $\Pi_{10} f(\bar{x}_{j})$ per i 701 punti equispaziati nell'intervallo.


        \item A questo punto, si hanno due vettori:
        \begin{itemize}
            \item \texttt{f(xj)} per i valori veri della funzione in 701 punti.
            \item \texttt{polyval(Pf, xj)} per i valori del polinomio interpolante negli stessi 701 punti.
        \end{itemize}
        Per calcolare l'errore, dobbiamo fare la differenza tra i valori veri e quelli interpolati:
        \begin{lstlisting}[language=MATLAB]
f(xj) - polyval(Pf, xj)\end{lstlisting}
        Il quale è il \textbf{vettore degli error puntuali} $E\left(\bar{x}_{j}\right)$. Infine, prendiamo il \textbf{massimo in valore assoluto} di questi errori, ovvero la norma infinito dell'errore di interpolazione.
    \end{itemize}
\end{enumerate}