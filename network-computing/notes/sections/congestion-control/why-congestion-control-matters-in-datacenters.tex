\section{Congestion Control}

\subsection{Why Congestion Control Matters in Datacenters}

Before touching TCP, DCTCP, or pFabric, we must understand \textbf{what congestion really is}.

\highspace
In general, congestion happens when the demand for a resource exceeds its capacity:
\begin{equation*}
    \textbf{Offered load} > \textbf{Available capacity}
\end{equation*}
In networks, senders inject packets faster than the network links can forward them.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{What happens inside a switch when congestion occurs?}}
\end{flushleft}
Each switch port has an \textbf{output link} with a certain capacity (e.g., 10 Gbps) and a \textbf{queue} (buffer) to hold packets waiting to be transmitted. If packets arrive faster than they can be transmitted:
\begin{enumerate}
    \item Packets accumulate in the queue, increasing \textbf{queueing delay}.
    \item Queue length grows, consuming more buffer space and potentially leading to \textbf{buffer overflow}.
    \item Delays increase as packets \textbf{wait longer in the queue}.
    \item Eventually, if the queue is full, incoming packets are \textbf{dropped}, leading to \textbf{packet loss}.
\end{enumerate}

\begin{flushleft}
    \textcolor{Red2}{\faIcon{exclamation-triangle} \textbf{Congestion $\ne$ Packet Loss}}
\end{flushleft}
While congestion can lead to packet loss, they are \textbf{not the same}. \textbf{Loss is a symptom of congestion}, but congestion can exist without loss if the queue is large enough to hold all incoming packets. \hl{Congestion starts when queue starts growing}, and \hl{loss happens when the queue becomes full}. This distinction is crucial for understanding how congestion control algorithms work, as they often rely on signals of congestion (like increased delay or packet loss) to adjust their sending rates.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Why is congestion control important in datacenters?}}
\end{flushleft}
In datacenters, congestion control is critical for several reasons:
\begin{itemize}
    \item \textbf{Performance}: Congestion can lead to increased latency and reduced throughput, which can degrade the performance of applications running in the datacenter.
    \item \textbf{Fairness}: Without congestion control, some flows may dominate the available bandwidth, leading to unfair resource allocation among different applications or users.
    \item \textbf{Resource Utilization}: Proper congestion control helps to maximize the utilization of network resources while minimizing the negative impacts of congestion.
    \item \textbf{Application Requirements}: Many datacenter applications have strict latency and throughput requirements, and congestion can cause them to miss deadlines or perform poorly.
\end{itemize}
The real goal of congestion control is not just avoiding packet loss, but rather \textbf{maintaining high performance and fairness} in the face of varying network conditions. This is why understanding congestion and its effects is essential for designing effective congestion control algorithms in datacenters.

\highspace
In summary, congestion control is crucial in datacenters to ensure that applications can perform well, resources are used efficiently, and fairness is maintained among different flows. Understanding the nature of congestion and its impact on network performance is key to developing effective congestion control strategies.