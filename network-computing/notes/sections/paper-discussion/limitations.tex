\subsection{Limitations}

Fastpass is powerful but not perfect.
\begin{itemize}
    \item \important{Scalability Limits}. There is a \textbf{single logical arbiter}. Even though it scales to 2.21 Tbps on 8 cores, that may not be enough for hyperscale datacenters. Furthermore, if the datacenter grows (more racks, more traffic, more scheduling requests), the arbiter might become a CPU bottleneck, a network bottleneck, and a latency bottleneck. So \hl{centralization always raises scalability questions.} 
    
    However, the paper suggests hierarchical arbitration (i.e., multiple Fastpass arbiters) as a potential solution, but it is not explored in depth. However, this solution would introduce additional complexity and overhead, and it is not clear how well it would perform in practice.
    
    
    \item \important{Timing Sensitivity}. Fastpass depends on precise time synchronization, PTP-level accuracy, and sub-microseconds alignment. If \hl{clocks drift}, the \hl{packets may arrive in wrong timeslots}, causing collisions and performance degradation (queue build-up, increased latency, and reduced throughput). The paper does not discuss how to handle clock drift or synchronization failures, which could be a significant issue in real-world deployments.
    
    
    \item \important{Small Packet Inefficiency}. The timeslot is 1 MTU transmission. If a flow sends \hl{very small packets} (e.g., 64 bytes), it will \hl{underutilize the timeslot}, leading to inefficient bandwidth usage and internal fragmentation at slot level. So Fastpass works best when packets are close to MTU size, and traffic is bulk-oriented (i.e., large flows). For workloads with very small RPC packets, Fastpass may waste capacity and increase latency (due to underutilization and fragmentation).
\end{itemize}