\subsubsection{Galerkin formulation}

Now we move from the \textbf{weak formulation} (still infinite-dimensional) to the \textbf{Galerkin formulation}, which is the bridge to something a computer can handle.

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon[regular]{lightbulb} \textbf{Galerkin idea}}
\end{flushleft}
We have a PDE that is too difficult to solve point by point. Therefore, we obtain a weaker form that is more flexible but still \textbf{infinite-dimensional} (function space). We use the \definition{Galerkin method}, which is a general approach for \textbf{approximating weak problems in finite-dimensional subspaces}.

\highspace
Take the weak formulation (\ref{eq: weak formulation}, page \pageref{eq: weak formulation}):
\begin{equation*}
    a(u,v) = F(v) \quad \forall v \in V
\end{equation*}
Restrict to a \textbf{finite-dimensional subspace} $V_h \subset V$, or $V_{h} \subset H_{0}^{1}$:
\begin{equation}
    a(u_h,v_h) = F(v_h) \quad \forall v_h \in V_h
\end{equation}
So, instead of ``all possible functions in $V$'', we only allow functions in $V_h$. And instead of infinitely many test functions, we only check the condition for test functions in $V_h$. So the \definition{Galerkin formulation} is:
\begin{equation}
    \text{Find } u_h \in V_h \;\; \text{such that } a(u_h,v_h) = F(v_h) \quad \forall v_h \in V_h
\end{equation}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{book} \textbf{In theory (mathematical meaning)}}
\end{flushleft}
This is a \textbf{projection}:
\begin{itemize}
    \item The true solution $u$ might not be in $V_h$.
    \item But we find the \textbf{closest approximation} $u_h$ in that space, such that the \textbf{residual is orthogonal to} $V_h$.
    \item That's why Galerkin works: the error $u-u_h$ is ``perpendicular'' to all test functions in $V_h$.
    
    \highspace
    When we require the error $e = u - u_{h}$ to be orthogonal to the approximation space $V_{h}$:
    \begin{equation*}
        a(e, v_h) = 0 \quad \forall v_h \in V_h
    \end{equation*}
    We are saying: ``\emph{the error has no component along any direction inside $V_{h}$}''. That's the analogue of the vector case, the shortest path from a point to a line is along the perpendicular. So Galerkin says: \emph{take the approximation $u_{h}$ such that the error is perpendicular to the chosen subspace}.
\end{itemize}
So in theory, Galerkin is just \textbf{orthogonal projection} of the weak problem onto a finite subspace.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=.9\textwidth]{img/poisson-1d/orthogonality-in-galerkin.pdf}
    \captionsetup{singlelinecheck=off}
    \caption[]{Orthogonality in Galerkin: Projection onto Subspace.
    \begin{itemize}
        \item The dashed line is our \textbf{approximation space $V_h$} (all the functions we can represent).
        \item The \textbf{blue vector} is the true solution $u$ (not in $V_{h}$).
        \item The \textbf{green vector} is the Galerkin approximation $u_{h}$, which lies in $V_{h}$.
        \item The \textbf{red vector} is the error $e = u - u_{h}$.
    \end{itemize}
    Notice: the red error is \textbf{perpendicular} to the line $V_{h}$. That's exactly what ``orthogonality of the residual'' means; \hl{Galerkin forces the error to be perpendicular to our chosen approximation space, ensuring the \emph{closest possible} approximation}.}
\end{figure}

\highspace
\begin{remarkbox}[: Orthogonality]
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{baby} \textbf{Orthogonality in high school math}}
    \end{flushleft}
    In Euclidean space ($\mathbb{R}^2, \mathbb{R}^3$), two vectors are \definition{Orthogonal} if their dot product is zero:
    \begin{equation}
        x \cdot y = 0    
    \end{equation}
    That means they are ``perpendicular''. Here, orthogonality means \emph{the shortest distance from a point to a line is the perpendicular}.

    \highspace
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Perpendicular?}} Take two vectors in the plane:
    \begin{equation*}
        u = (u_1, u_2), \quad v = (v_1, v_2)
    \end{equation*}
    Their dot product is:
    \begin{equation*}
        u \cdot v = u_1 v_1 + u_2 v_2
    \end{equation*}
    Now, recall the formula with the angle $\theta$ between them:
    \begin{equation*}
        u \cdot v = \left\| u \right\| \, \left\| v \right\| \cos\left(\theta\right)
    \end{equation*}
    So:
    \begin{itemize}
        \item If $u \cdot v > 0$, $\text{angle} < 90^{\circ}$.
        \item If $u \cdot v < 0$, $\text{angle} > 90^{\circ}$.
        \item If $u \cdot v = 0$, then $\cos \theta = 0$, then $\theta = 90^{\circ}$.
    \end{itemize}
    That's exactly why ``orthogonal'' means ``perpendicular'': the inner product vanishes when vectors meet at a right angle.

    \highspace
    \begin{flushleft}
        \textcolor{Green3}{\faIcon{superscript} \textbf{Orthogonality in function spaces}}
    \end{flushleft}
    Now, when we move from vectors to \textbf{functions}, the dot product is replaced by an \textbf{inner product}. For example, in $L^{2}\left(0,1\right)$ (square-integrable functions), the inner product is:
    \begin{equation*}
        \left(u,v\right) = \displaystyle\int_{0}^{1} u\left(x\right) \cdot v\left(x\right) \, \mathrm{d}x
    \end{equation*}
    So two functions $u, v$ are \definition{Orthogonal} if:
    \begin{equation*}
        \displaystyle\int_{0}^{1} u\left(x\right) \cdot v\left(x\right) \, \mathrm{d}x = 0    
    \end{equation*}
    This is the function-space version of ``perpendicular''. Here, orthogonality means \emph{the Galerkin solution $u_{h}$ is the closest function in $V_{h}$ to the true solution $u$, with distance measured in the PDE's energy norm}.
\end{remarkbox}

\newpage

\noindent
That's the \definition{Galerkin formulation}.
\begin{itemize}
    \item The exact solution $u$ lives in $V$ (infinite world).
    \item The approximate solution $u_h$ lives in $V_h$ (finite world).
    \item We require the weak form to hold for all test functions in $V_h$.
\end{itemize}

\highspace
\begin{flushleft}
    \textcolor{Green3}{\faIcon{question-circle} \textbf{Choosing $V_h$}}
\end{flushleft}
The \textbf{true solution} lives in an \emph{infinite-dimensional world} (all possible admissible functions). We cannot compute in infinity. So we \textbf{pick a smaller world}, a \emph{finite-dimensional subspace} $V_{h}$. That smaller world is where Galerkin will search for the approximate solution $u_{h}$.

\highspace
\textcolor{Green3}{\faIcon{question-circle} \textbf{What is $V_{h}$ really?}} Think of $V_{h}$ as our \textbf{toolbox of functions}. It's the set of shapes that our approximation is based on. For example:
\begin{itemize}
    \item If we choose \textbf{straight lines} between mesh points, $V_h$ are piecewise linear functions.
    \item If we choose \textbf{parabolas} on each mesh cell, $V_h$ are piecewise quadratic functions.
    \item If we choose \textbf{sines and cosines}, $V_h$ are trigonometric polynomials (spectral method).
\end{itemize}
In our laboratory, $V_{h}$ is always:
\begin{gather*}
    V_h = \{\text{functions that are continuous and piecewise polynomials on a mesh,} \\
    \text{with } u = 0 \text{ at the boundary}\}
\end{gather*}

\highspace
\textcolor{Green3}{\faIcon{question-circle} \textbf{Why do we care about which $V_{h}$?}} Because:
\begin{itemize}
    \item A \textbf{bad choice} of $V_{h}$: we cannot approximate the solution well.
    \item A \textbf{good choice} of $V_{h}$: as we refine (smaller mesh, higher polynomial degree), the approximation converges to the true solution.
\end{itemize}
So the whole art of finite element is: \emph{how do we design $V_{h}$ so that it's expressive enough but still computable?}
\begin{itemize}
    \item Domain: $\left(0, 1\right)$.
    \item Mesh: cut into $N$ intervals.
    \item $\left(V_{h}\right)$: functions that are continuous, zero at the ends, and linear on each small interval.
    \item Approximation space:
    \begin{equation*}
        V_{h} = \left\{ v \in C^0([0,1]) : v|_{K} \in \mathbb{P}_1, \, \forall K \in \mathcal{T}_h, \, v(0)=v(1)=0 \right\}
    \end{equation*}
    \begin{deepeningbox}[: Where does $V_{h}$ come from?]
        From the previous sections, we had the following:
        \begin{equation*}
            \text{Find } u \in V = H_{0}^{1}\left(0,1\right) \quad \text{such that } a\left(u,v\right) = F\left(v\right) \;\; \forall v \in V
        \end{equation*}
        So the exact solution lives in:
        \begin{equation*}
            V = H_{0}^{1}\left(0,1\right) = \left\{ v \in L^{2}\left(0,1\right): v' \in L^{2}\left(0,1\right), v\left(0\right) = v\left(1\right) = 0 \right\}
        \end{equation*}
        This space is \textbf{infinite-dimensional} (all functions with square-integrable derivative, vanishing at endpoints).

        \highspace
        We want a \textbf{finite-dimensional} subspace $V_{h} \subset V$. So we must impose two things: (1) \important{boundary condition} (keep $v(0)=v(1)=0$, so that $V_h \subset H_0^1$), (2) \important{finite dimension} (instead of ``all functions'', choose a restricted family of functions easy to handle).
        \begin{enumerate}
            \item \important{Choose a \emph{mesh}.} Split $[0,1]$ into small subintervals:
            \begin{equation*}
                \mathcal{T}_{h} = \left\{K_{1}, K_{2}, \dots, K_{N}\right\}, \quad K_{i} = \left[x_{i-1}, x_{i}\right]
            \end{equation*}
            Here $h = \max_i \left|K_{i}\right|$ is the \textbf{mesh size}.

            \item \important{Choose a \emph{polynomial degree}.} On each element $K$, we allow only polynomials of degree $\leq r$.
            \begin{itemize}
                \item If $r=1$: linear functions on each element.
                \item If $r=2$: quadratics.
                \item And so on.
            \end{itemize}
            This is written as $v|_{K} \in \mathbb{P}_{r}$.

            \item \important{Impose continuity.} Finite element functions are not just piecewise polynomials: they must be \textbf{globally continuous} (otherwise they wouldn't belong to $H_{0}^{1}$). So we require $v \in C^{0}\left(\left[0,1\right]\right)$.

            \item \important{Impose boundary conditions.} Finally, we enforce $v(0)=v(1)=0$ to respect the homogeneous Dirichlet boundary conditions.
        \end{enumerate}
        So the space is:
        \begin{equation*}
            V_{h} = \left\{ v \in C^{0}\left(\left[0,1\right]\right) : v|_{K} \in \mathbb{P}_{r}, \; \forall K \in \mathcal{T}_{h}, \; v(0)=v(1)=0 \right\}
        \end{equation*}
        If $r=1$, that's piecewise linear FE functions. If $r=2$, piecewise quadratic, and so on. In summary, we obtain the formula for $V_{h}$ by restricting the infinite weak space $V = H_{0}^{1}$ in 4 steps: first, we \emph{mesh} the domain. Then, on each mesh cell, we allow only low-degree polynomials. Next, we glue them together with continuity. Finally, we impose boundary conditions. That's exactly the standard definition of a finite element space.
    \end{deepeningbox}
\end{itemize}
